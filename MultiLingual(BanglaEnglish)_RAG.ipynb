{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6ee0e6b7",
   "metadata": {},
   "source": [
    "### 1.SETUP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d3a91b26",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.3 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting PyPDF2\n",
      "  Downloading pypdf2-3.0.1-py3-none-any.whl (232 kB)\n",
      "     ------------------------------------ 232.6/232.6 kB 712.6 kB/s eta 0:00:00\n",
      "Requirement already satisfied: sentence-transformers in c:\\users\\user\\rag_env\\lib\\site-packages (5.0.0)\n",
      "Collecting chromadb\n",
      "  Using cached chromadb-1.0.15-cp39-abi3-win_amd64.whl (19.5 MB)\n",
      "Collecting fastapi\n",
      "  Using cached fastapi-0.116.1-py3-none-any.whl (95 kB)\n",
      "Collecting uvicorn\n",
      "  Using cached uvicorn-0.35.0-py3-none-any.whl (66 kB)\n",
      "Collecting ollama\n",
      "  Downloading ollama-0.5.1-py3-none-any.whl (13 kB)\n",
      "Requirement already satisfied: numpy in c:\\users\\user\\rag_env\\lib\\site-packages (2.3.2)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\user\\rag_env\\lib\\site-packages (1.7.1)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in c:\\users\\user\\rag_env\\lib\\site-packages (from sentence-transformers) (4.53.3)\n",
      "Requirement already satisfied: tqdm in c:\\users\\user\\rag_env\\lib\\site-packages (from sentence-transformers) (4.67.1)\n",
      "Requirement already satisfied: torch>=1.11.0 in c:\\users\\user\\rag_env\\lib\\site-packages (from sentence-transformers) (2.7.1)\n",
      "Requirement already satisfied: scipy in c:\\users\\user\\rag_env\\lib\\site-packages (from sentence-transformers) (1.16.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.20.0 in c:\\users\\user\\rag_env\\lib\\site-packages (from sentence-transformers) (0.33.5)\n",
      "Requirement already satisfied: Pillow in c:\\users\\user\\rag_env\\lib\\site-packages (from sentence-transformers) (11.3.0)\n",
      "Requirement already satisfied: typing_extensions>=4.5.0 in c:\\users\\user\\rag_env\\lib\\site-packages (from sentence-transformers) (4.14.1)\n",
      "Collecting build>=1.0.3\n",
      "  Using cached build-1.2.2.post1-py3-none-any.whl (22 kB)\n",
      "Requirement already satisfied: pydantic>=1.9 in c:\\users\\user\\rag_env\\lib\\site-packages (from chromadb) (2.11.7)\n",
      "Collecting pybase64>=1.4.1\n",
      "  Using cached pybase64-1.4.1-cp311-cp311-win_amd64.whl (36 kB)\n",
      "Collecting posthog<6.0.0,>=2.4.0\n",
      "  Using cached posthog-5.4.0-py3-none-any.whl (105 kB)\n",
      "Collecting onnxruntime>=1.14.1\n",
      "  Using cached onnxruntime-1.22.1-cp311-cp311-win_amd64.whl (12.7 MB)\n",
      "Collecting opentelemetry-api>=1.2.0\n",
      "  Using cached opentelemetry_api-1.35.0-py3-none-any.whl (65 kB)\n",
      "Collecting opentelemetry-exporter-otlp-proto-grpc>=1.2.0\n",
      "  Using cached opentelemetry_exporter_otlp_proto_grpc-1.35.0-py3-none-any.whl (18 kB)\n",
      "Collecting opentelemetry-sdk>=1.2.0\n",
      "  Using cached opentelemetry_sdk-1.35.0-py3-none-any.whl (119 kB)\n",
      "Requirement already satisfied: tokenizers>=0.13.2 in c:\\users\\user\\rag_env\\lib\\site-packages (from chromadb) (0.15.2)\n",
      "Collecting pypika>=0.48.9\n",
      "  Using cached pypika-0.48.9-py2.py3-none-any.whl\n",
      "Requirement already satisfied: overrides>=7.3.1 in c:\\users\\user\\rag_env\\lib\\site-packages (from chromadb) (7.7.0)\n",
      "Collecting importlib-resources\n",
      "  Using cached importlib_resources-6.5.2-py3-none-any.whl (37 kB)\n",
      "Collecting grpcio>=1.58.0\n",
      "  Downloading grpcio-1.74.0-cp311-cp311-win_amd64.whl (4.5 MB)\n",
      "     ---------------------------------------- 4.5/4.5 MB 1.9 MB/s eta 0:00:00\n",
      "Collecting bcrypt>=4.0.1\n",
      "  Using cached bcrypt-4.3.0-cp39-abi3-win_amd64.whl (152 kB)\n",
      "Collecting typer>=0.9.0\n",
      "  Downloading typer-0.16.0-py3-none-any.whl (46 kB)\n",
      "     ---------------------------------------- 46.3/46.3 kB 1.2 MB/s eta 0:00:00\n",
      "Collecting kubernetes>=28.1.0\n",
      "  Using cached kubernetes-33.1.0-py2.py3-none-any.whl (1.9 MB)\n",
      "Requirement already satisfied: tenacity>=8.2.3 in c:\\users\\user\\rag_env\\lib\\site-packages (from chromadb) (9.1.2)\n",
      "Requirement already satisfied: pyyaml>=6.0.0 in c:\\users\\user\\rag_env\\lib\\site-packages (from chromadb) (6.0.2)\n",
      "Collecting mmh3>=4.0.1\n",
      "  Using cached mmh3-5.1.0-cp311-cp311-win_amd64.whl (41 kB)\n",
      "Requirement already satisfied: orjson>=3.9.12 in c:\\users\\user\\rag_env\\lib\\site-packages (from chromadb) (3.11.0)\n",
      "Requirement already satisfied: httpx>=0.27.0 in c:\\users\\user\\rag_env\\lib\\site-packages (from chromadb) (0.28.1)\n",
      "Collecting rich>=10.11.0\n",
      "  Downloading rich-14.1.0-py3-none-any.whl (243 kB)\n",
      "     -------------------------------------- 243.4/243.4 kB 2.1 MB/s eta 0:00:00\n",
      "Requirement already satisfied: jsonschema>=4.19.0 in c:\\users\\user\\rag_env\\lib\\site-packages (from chromadb) (4.25.0)\n",
      "Collecting starlette<0.48.0,>=0.40.0\n",
      "  Using cached starlette-0.47.2-py3-none-any.whl (72 kB)\n",
      "Collecting click>=7.0\n",
      "  Downloading click-8.2.1-py3-none-any.whl (102 kB)\n",
      "     -------------------------------------- 102.2/102.2 kB 2.0 MB/s eta 0:00:00\n",
      "Requirement already satisfied: h11>=0.8 in c:\\users\\user\\rag_env\\lib\\site-packages (from uvicorn) (0.16.0)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\user\\rag_env\\lib\\site-packages (from scikit-learn) (1.5.1)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\user\\rag_env\\lib\\site-packages (from scikit-learn) (3.6.0)\n",
      "Requirement already satisfied: packaging>=19.1 in c:\\users\\user\\rag_env\\lib\\site-packages (from build>=1.0.3->chromadb) (25.0)\n",
      "Collecting pyproject_hooks\n",
      "  Using cached pyproject_hooks-1.2.0-py3-none-any.whl (10 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\user\\rag_env\\lib\\site-packages (from build>=1.0.3->chromadb) (0.4.6)\n",
      "Requirement already satisfied: anyio in c:\\users\\user\\rag_env\\lib\\site-packages (from httpx>=0.27.0->chromadb) (4.9.0)\n",
      "Requirement already satisfied: certifi in c:\\users\\user\\rag_env\\lib\\site-packages (from httpx>=0.27.0->chromadb) (2025.7.14)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\user\\rag_env\\lib\\site-packages (from httpx>=0.27.0->chromadb) (1.0.9)\n",
      "Requirement already satisfied: idna in c:\\users\\user\\rag_env\\lib\\site-packages (from httpx>=0.27.0->chromadb) (3.10)\n",
      "Requirement already satisfied: filelock in c:\\users\\user\\rag_env\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.18.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\user\\rag_env\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2025.3.0)\n",
      "Requirement already satisfied: requests in c:\\users\\user\\rag_env\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2.32.4)\n",
      "Requirement already satisfied: attrs>=22.2.0 in c:\\users\\user\\rag_env\\lib\\site-packages (from jsonschema>=4.19.0->chromadb) (25.3.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in c:\\users\\user\\rag_env\\lib\\site-packages (from jsonschema>=4.19.0->chromadb) (2025.4.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in c:\\users\\user\\rag_env\\lib\\site-packages (from jsonschema>=4.19.0->chromadb) (0.36.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in c:\\users\\user\\rag_env\\lib\\site-packages (from jsonschema>=4.19.0->chromadb) (0.26.0)\n",
      "Requirement already satisfied: six>=1.9.0 in c:\\users\\user\\rag_env\\lib\\site-packages (from kubernetes>=28.1.0->chromadb) (1.17.0)\n",
      "Requirement already satisfied: python-dateutil>=2.5.3 in c:\\users\\user\\rag_env\\lib\\site-packages (from kubernetes>=28.1.0->chromadb) (2.9.0.post0)\n",
      "Collecting google-auth>=1.0.1\n",
      "  Using cached google_auth-2.40.3-py2.py3-none-any.whl (216 kB)\n",
      "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in c:\\users\\user\\rag_env\\lib\\site-packages (from kubernetes>=28.1.0->chromadb) (1.8.0)\n",
      "Collecting requests-oauthlib\n",
      "  Using cached requests_oauthlib-2.0.0-py2.py3-none-any.whl (24 kB)\n",
      "Collecting oauthlib>=3.2.2\n",
      "  Using cached oauthlib-3.3.1-py3-none-any.whl (160 kB)\n",
      "Requirement already satisfied: urllib3>=1.24.2 in c:\\users\\user\\rag_env\\lib\\site-packages (from kubernetes>=28.1.0->chromadb) (2.5.0)\n",
      "Collecting durationpy>=0.7\n",
      "  Using cached durationpy-0.10-py3-none-any.whl (3.9 kB)\n",
      "Collecting coloredlogs\n",
      "  Using cached coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
      "Collecting flatbuffers\n",
      "  Using cached flatbuffers-25.2.10-py2.py3-none-any.whl (30 kB)\n",
      "Collecting protobuf\n",
      "  Downloading protobuf-6.31.1-cp310-abi3-win_amd64.whl (435 kB)\n",
      "     -------------------------------------- 435.3/435.3 kB 2.3 MB/s eta 0:00:00\n",
      "Requirement already satisfied: sympy in c:\\users\\user\\rag_env\\lib\\site-packages (from onnxruntime>=1.14.1->chromadb) (1.14.0)\n",
      "Collecting importlib-metadata<8.8.0,>=6.0\n",
      "  Using cached importlib_metadata-8.7.0-py3-none-any.whl (27 kB)\n",
      "Collecting googleapis-common-protos~=1.57\n",
      "  Using cached googleapis_common_protos-1.70.0-py3-none-any.whl (294 kB)\n",
      "Collecting opentelemetry-exporter-otlp-proto-common==1.35.0\n",
      "  Using cached opentelemetry_exporter_otlp_proto_common-1.35.0-py3-none-any.whl (18 kB)\n",
      "Collecting opentelemetry-proto==1.35.0\n",
      "  Using cached opentelemetry_proto-1.35.0-py3-none-any.whl (72 kB)\n",
      "Collecting opentelemetry-semantic-conventions==0.56b0\n",
      "  Using cached opentelemetry_semantic_conventions-0.56b0-py3-none-any.whl (201 kB)\n",
      "Collecting backoff>=1.10.0\n",
      "  Using cached backoff-2.2.1-py3-none-any.whl (15 kB)\n",
      "Collecting distro>=1.5.0\n",
      "  Using cached distro-1.9.0-py3-none-any.whl (20 kB)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\user\\rag_env\\lib\\site-packages (from pydantic>=1.9->chromadb) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in c:\\users\\user\\rag_env\\lib\\site-packages (from pydantic>=1.9->chromadb) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\users\\user\\rag_env\\lib\\site-packages (from pydantic>=1.9->chromadb) (0.4.1)\n",
      "Collecting markdown-it-py>=2.2.0\n",
      "  Downloading markdown_it_py-3.0.0-py3-none-any.whl (87 kB)\n",
      "     --------------------------------------- 87.5/87.5 kB 52.1 kB/s eta 0:00:00\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\user\\rag_env\\lib\\site-packages (from rich>=10.11.0->chromadb) (2.19.2)\n",
      "Requirement already satisfied: networkx in c:\\users\\user\\rag_env\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (3.5)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\user\\rag_env\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (3.1.6)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\user\\rag_env\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.11.6)\n",
      "Collecting tokenizers>=0.13.2\n",
      "  Using cached tokenizers-0.21.2-cp39-abi3-win_amd64.whl (2.5 MB)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in c:\\users\\user\\rag_env\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.5.3)\n",
      "Collecting shellingham>=1.3.0\n",
      "  Downloading shellingham-1.5.4-py2.py3-none-any.whl (9.8 kB)\n",
      "Collecting httptools>=0.6.3\n",
      "  Using cached httptools-0.6.4-cp311-cp311-win_amd64.whl (88 kB)\n",
      "Collecting python-dotenv>=0.13\n",
      "  Downloading python_dotenv-1.1.1-py3-none-any.whl (20 kB)\n",
      "Collecting watchfiles>=0.13\n",
      "  Using cached watchfiles-1.1.0-cp311-cp311-win_amd64.whl (292 kB)\n",
      "Collecting websockets>=10.4\n",
      "  Using cached websockets-15.0.1-cp311-cp311-win_amd64.whl (176 kB)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\user\\rag_env\\lib\\site-packages (from anyio->httpx>=0.27.0->chromadb) (1.3.1)\n",
      "Collecting cachetools<6.0,>=2.0.0\n",
      "  Downloading cachetools-5.5.2-py3-none-any.whl (10 kB)\n",
      "Collecting pyasn1-modules>=0.2.1\n",
      "  Using cached pyasn1_modules-0.4.2-py3-none-any.whl (181 kB)\n",
      "Collecting rsa<5,>=3.1.4\n",
      "  Using cached rsa-4.9.1-py3-none-any.whl (34 kB)\n",
      "Collecting zipp>=3.20\n",
      "  Using cached zipp-3.23.0-py3-none-any.whl (10 kB)\n",
      "Collecting mdurl~=0.1\n",
      "  Downloading mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\user\\rag_env\\lib\\site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.4.2)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\user\\rag_env\\lib\\site-packages (from sympy->onnxruntime>=1.14.1->chromadb) (1.3.0)\n",
      "Collecting humanfriendly>=9.1\n",
      "  Using cached humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\user\\rag_env\\lib\\site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.2)\n",
      "Collecting pyreadline3\n",
      "  Using cached pyreadline3-3.5.4-py3-none-any.whl (83 kB)\n",
      "Collecting pyasn1<0.7.0,>=0.6.1\n",
      "  Using cached pyasn1-0.6.1-py3-none-any.whl (83 kB)\n",
      "Installing collected packages: pypika, flatbuffers, durationpy, zipp, websockets, shellingham, python-dotenv, pyreadline3, pyproject_hooks, PyPDF2, pybase64, pyasn1, protobuf, oauthlib, mmh3, mdurl, importlib-resources, httptools, grpcio, distro, click, cachetools, bcrypt, backoff, watchfiles, uvicorn, starlette, rsa, requests-oauthlib, pyasn1-modules, posthog, opentelemetry-proto, markdown-it-py, importlib-metadata, humanfriendly, googleapis-common-protos, build, tokenizers, rich, opentelemetry-exporter-otlp-proto-common, opentelemetry-api, ollama, google-auth, fastapi, coloredlogs, typer, opentelemetry-semantic-conventions, onnxruntime, kubernetes, opentelemetry-sdk, opentelemetry-exporter-otlp-proto-grpc, chromadb\n",
      "  Attempting uninstall: tokenizers\n",
      "    Found existing installation: tokenizers 0.15.2\n",
      "    Uninstalling tokenizers-0.15.2:\n",
      "      Successfully uninstalled tokenizers-0.15.2\n",
      "Successfully installed PyPDF2-3.0.1 backoff-2.2.1 bcrypt-4.3.0 build-1.2.2.post1 cachetools-5.5.2 chromadb-1.0.15 click-8.2.1 coloredlogs-15.0.1 distro-1.9.0 durationpy-0.10 fastapi-0.116.1 flatbuffers-25.2.10 google-auth-2.40.3 googleapis-common-protos-1.70.0 grpcio-1.74.0 httptools-0.6.4 humanfriendly-10.0 importlib-metadata-8.7.0 importlib-resources-6.5.2 kubernetes-33.1.0 markdown-it-py-3.0.0 mdurl-0.1.2 mmh3-5.1.0 oauthlib-3.3.1 ollama-0.5.1 onnxruntime-1.22.1 opentelemetry-api-1.35.0 opentelemetry-exporter-otlp-proto-common-1.35.0 opentelemetry-exporter-otlp-proto-grpc-1.35.0 opentelemetry-proto-1.35.0 opentelemetry-sdk-1.35.0 opentelemetry-semantic-conventions-0.56b0 posthog-5.4.0 protobuf-6.31.1 pyasn1-0.6.1 pyasn1-modules-0.4.2 pybase64-1.4.1 pypika-0.48.9 pyproject_hooks-1.2.0 pyreadline3-3.5.4 python-dotenv-1.1.1 requests-oauthlib-2.0.0 rich-14.1.0 rsa-4.9.1 shellingham-1.5.4 starlette-0.47.2 tokenizers-0.21.2 typer-0.16.0 uvicorn-0.35.0 watchfiles-1.1.0 websockets-15.0.1 zipp-3.23.0\n"
     ]
    }
   ],
   "source": [
    "!pip install PyPDF2 sentence-transformers chromadb fastapi uvicorn ollama numpy scikit-learn\n",
    "import PyPDF2\n",
    "import re\n",
    "import json\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import chromadb\n",
    "from chromadb.utils import embedding_functions\n",
    "import ollama\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from fastapi import FastAPI, HTTPException\n",
    "import uvicorn\n",
    "import asyncio\n",
    "from pydantic import BaseModel\n",
    "import logging\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4b6879a",
   "metadata": {},
   "source": [
    "### 2: Text Extraction and Dataset Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fe6e6ccf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Text extraction and QA dataset loading completed.\n"
     ]
    }
   ],
   "source": [
    "def extract_text_from_pdf(pdf_path):\n",
    "    try:\n",
    "        with open(pdf_path, 'rb') as file:\n",
    "            reader = PyPDF2.PdfReader(file)\n",
    "            text = ''\n",
    "            for page in reader.pages:\n",
    "                page_text = page.extract_text() or ''\n",
    "                # Clean text: remove repetitive characters and normalize whitespace\n",
    "                cleaned_text = re.sub(r'(\\w)\\1{2,}', '', page_text)\n",
    "                cleaned_text = re.sub(r'\\s+', ' ', cleaned_text)\n",
    "                text += cleaned_text + ' '\n",
    "        return text.strip()\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error extracting text from PDF: {e}\")\n",
    "        return ''\n",
    "\n",
    "# Simulate extracted text due to garbled PDF content\n",
    "sample_pdf_text = \"\"\"\n",
    "অমর সেনের থিসিসে জলবায়ু পরিবর্তন এবং এর অর্থনৈতিক প্রভাব নিয়ে আলোচনা করা হয়েছে। \n",
    "তিনি ম্যাথমেটিক্যাল মডেলিং ব্যবহার করে বিশ্লেষণ করেছেন। \n",
    "তার কাজের জন্য ২০১৮ সালে তিনি নোবেল পুরস্কার পান।\n",
    "Amartya Sen's thesis discusses climate change and its economic impacts. \n",
    "He used mathematical modeling for analysis. \n",
    "He received the Nobel Prize in 2018 for his work.\n",
    "\"\"\"\n",
    "\n",
    "# Load QA dataset\n",
    "def load_qa_dataset(json_path):\n",
    "    try:\n",
    "        with open(json_path, 'r', encoding='utf-8') as f:\n",
    "            data = json.load(f)\n",
    "        # Combine Bengali and English QA pairs\n",
    "        qa_texts = []\n",
    "        for pair in data['bangla_qa_pairs'] + data['english_qa_pairs']:\n",
    "            qa_texts.append(f\"Context: {pair['context']}\\nQuestion: {pair['question']}\\nAnswer: {pair['answer']}\")\n",
    "        return qa_texts\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error loading QA dataset: {e}\")\n",
    "        return []\n",
    "\n",
    "# Combine PDF text and QA dataset\n",
    "pdf_text = sample_pdf_text  # Replace with extract_text_from_pdf('HSC26-Bangla1st-Paper.pdf') if PDF is available\n",
    "qa_texts = load_qa_dataset('bangla_english_qa_dataset.json')\n",
    "corpus_text = pdf_text + '\\n' + '\\n'.join(qa_texts)\n",
    "logger.info(\"Text extraction and QA dataset loading completed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff886820",
   "metadata": {},
   "source": [
    "###  3: Document Chunking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dfcea69b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Created 123 chunks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 1: অমর সেনের থিসিসে জলবায়ু পরিবর্তন এবং এর অর্থনৈতিক প্রভাব নিয়ে আলোচনা করা হয়েছে। তিনি ম্যাথমেটিক্যাল মডেলিং ব্যবহার করে বিশ্লেষণ করেছেন। তার কাজের জন্য ২০১৮ সালে তিনি নোবেল পুরস্কার পান।\n",
      "Chunk 2: Amartya Sen's thesis discusses climate change and its economic impacts. He used mathematical modeling for analysis. He received the Nobel Prize in 2018 for his work. Context: আমার বয়স সাতার মাত্র।\n",
      "Chunk 3: এই জীবনটা না দদীঘিযি হাসাবে ব্যে, না গুনি হাসাবে। তবু ইহার একটু বিশেষ মূল্য আছে।\n",
      "Chunk 4: ইহা যেই ফুলের মতা যাহার বুক্কি উপরি ভ্রমর আর্স া ব্র্স ারিল, এবং যেই পদক্ষেপি ইতিহাস তাহার জীবনের মাঝখানে ফুলের মতা গুটি ধরিয়া উঠি াছে। Question: অনুপম তার জীবনের মূল্য সম্পর্কে কী বলেছেন?\n",
      "Chunk 5: Answer: অনুপম বলেছেন যে তার জীবন দীর্ঘ বা গুণে হাসাবে নয়, তবে এর একটু বিশেষ মূল্য আছে, যেমন একটি ফুলের মতো যার উপর ভ্রমর এসেছে এবং যার জীবনের মাঝখানে ইতিহাস ফুলের মতো গুটি ধরেছে।\n"
     ]
    }
   ],
   "source": [
    "def chunk_text(text, max_chunk_size=200):\n",
    "    sentences = re.split(r'(?<=[।.!?])\\s+', text)\n",
    "    chunks = []\n",
    "    current_chunk = ''\n",
    "    for sentence in sentences:\n",
    "        if len(current_chunk) + len(sentence) <= max_chunk_size:\n",
    "            current_chunk += sentence + ' '\n",
    "        else:\n",
    "            if current_chunk:\n",
    "                chunks.append(current_chunk.strip())\n",
    "                current_chunk = sentence + ' '\n",
    "    if current_chunk:\n",
    "        chunks.append(current_chunk.strip())\n",
    "    return chunks\n",
    "\n",
    "chunks = chunk_text(corpus_text)\n",
    "logger.info(f\"Created {len(chunks)} chunks.\")\n",
    "for i, chunk in enumerate(chunks[:5]):  # Show first 5 chunks for brevity\n",
    "    print(f\"Chunk {i+1}: {chunk}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6229c059",
   "metadata": {},
   "source": [
    "###  4: Vectorization and Storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5286e2ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sentence_transformers.SentenceTransformer:Use pytorch device_name: cpu\n",
      "INFO:sentence_transformers.SentenceTransformer:Load pretrained SentenceTransformer: paraphrase-multilingual-MiniLM-L12-v2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b51b65f7d03742b691efda16f402ba7b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modules.json:   0%|          | 0.00/229 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\rag_env\\Lib\\site-packages\\huggingface_hub\\file_download.py:143: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\User\\.cache\\huggingface\\hub\\models--sentence-transformers--paraphrase-multilingual-MiniLM-L12-v2. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "01b9bb23552e4dd7a8593c076b8719ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config_sentence_transformers.json:   0%|          | 0.00/122 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a3a7375ce404c8f9a3a339032337368",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f6ddbfea5e5f4e33ae22cce1b97ba5b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2399d0ded53945e886ad95452e8428a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/645 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c5a122e44d24f3fb9cbcb57a08997e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/471M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12770ba035c347a585138ec42807d944",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/480 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "74c3a4e7e63b48129c4d3ccad09ef520",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/9.08M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a1fdde43412c46f0888bebc43fc59f8d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/239 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8283350ae1e44b1ba6969b125d2cc7ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:chromadb.telemetry.product.posthog:Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.\n",
      "INFO:sentence_transformers.SentenceTransformer:Load pretrained SentenceTransformer: paraphrase-multilingual-MiniLM-L12-v2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e3713753955a4bfc947623842cd294ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "36e8cee28ba94e54beb2cfc95036026f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "13f221b55c8b499eae8727997727227f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c5749738cd54ca0ab414192b7fffd74",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "46e06a19e9464ed8b5f798bb5ff56f3f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d366c8acbc5462998c1d59bc700f6f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "121dbdd8fbd145b4aa3aa4e1c9233051",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6eaddce894d469bbc8d2190c5497351",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c5ed9bc3dc0c4ea6b4313c0b5dc444dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb37f1e9b1674eb1acbe4379337dc1cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0f09f75b307419db3606c5485ca6d68",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1fb8db848cee4f8aa7b6fb2756d7120f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd6a08a436604ca79e794568f6c3bb0e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ff3aa47ec48482bace631fd39c8fa20",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9ed9287b54f4d99a082ba74231206b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dcf74c0cc328498689f33b3590b307a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d303d39b63794936b10d1aa56295488e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "936151f2643f4ef3b62390f17e680f2e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07f9b846d98d4e7bbe900a427adbb606",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa8c3f63fb354bef8b40363d69a67d7d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "abcb8b07dc48470c8e30b9248575bf07",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "172c7b201b704bd389e5b37c4f38a57e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "086698d5aaf74f7597cd6741ee98c528",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9a9c60cf6f14d2595f119804f2280fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a43e4063aaab4992abad9a7870105e93",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "35faa46d4c824ee39af81377ae2f9b3b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d8cceb579c354a09894a2691c60d02d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "012971eb72df413dbc5076ff742ea7c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "596445fccef543ee9ba1cc8f085118ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3bb9c86ea0874e09b34d0cb99fa8fa70",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "27a39a5af26540659fa8c10b34927aa7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ff618c788dd425bba0e0fe55ef738cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f7c685869c094737bc8999dfd7f92380",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76d252a5c4564bb6b3392af758154d0b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f349d17ccd24f56a0a951ac8e6fddcf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "03451bb18c944d85b2158d0784df358e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f346262137db402599db1d44a5cf555f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69e04fa74cbf4d40b4ee71a045f1df15",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e084dfd650c449f8749ed41cfec1782",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3976cf9a9c2544e6a94004d0959b51a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ebcd9e04b17e4e1d8d8df7e21e6acb6b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96e20d272aa442498af958e223afb486",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "36b24ba0d3a447609a3b657ab05eb586",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c37cd9762f04681a7e596f39d394239",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5883a419ced746e9b126a31c73b4b60b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ea1af17485346a7890ef95c225f9fec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "795270df4b2a43e28e4ad912d67bcbec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba01f0a9239d4930a64df6e1e11ce184",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c4688b9afe26485fa0e3d617847d6683",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "74672f97bb93441b98af07e46174f1b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0402737de82f4e33a41b509cbf7bf700",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "778e969523ed4ccdb1af9cbd061be290",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "557836b3732a41a9b6e44ed096bc87e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24325894606444d381998ee3a4c49736",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c2c0c74dec640afa5a0f0e8b5b6dae2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32140962e0fb4ffda7ccac237ec68279",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0e16d14669d4e09b4eaa898a8d4fe86",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6aa93868578a43ea829a945e59a47893",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "13fba75bd20047a7aaa7377524f69dc3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4703e21033854ddfa8f85da4688559c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22426ad0727549a6ae0269eb38aaa3b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac89bbcf99774081b64ef1f9cd21b279",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed46605d4e7848bba9b90a755c61a2b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "03c6ca5fe3474f2b89d0a18569802a02",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "387f1f98cf004cd6a170ca5fba301e0d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "298b74098b434b639bfcf0483af6b109",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "669f26fc809849949b927c46674463ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a3e7310a9994288a0fed179b58f7b98",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c6262a8c04c47fd9f0f1e934a0706f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c2a8beeadab49deb99d2c1f7fbdf4e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ccb4222fe3144f985dfc22b7dd232c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d05c332a31949469f2d91f699a1732b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b574bb9a0e14b829cecf853c6cefd4f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56056a3514c646b998a01960e6c1ebd9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7f8b64b51b849d985daeebf3a66d487",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "19a0afaa90ba4b40b0cc5a80ca0e725a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "663fdff989cd4a01aef926de4355b929",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4617b5e32887484b91f04b7932a37c76",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5110b5709ce5438294acb5b9e42a28e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "275f1602f12a4467bc997f1595973d8e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0487a265a84e4be694d886798baa72a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "abb2ca6eb4ff476b824c5314df1c4b23",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63514201ea8c4d06bf6cd8b84fe3e646",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69e46412a74646508707c57b80bcceaa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "491d0caeef72470a93b6f371d29e95f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c8d6801a24f42cbb76031f7fbb2d400",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02ef5fc156844dc1bed7f8e2e8efc7f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "99b1e77abe0343d69839e5a6d6f86e39",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "00543482bca544ef9f87e534dde4fd8c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f41dc9e39da4a67801f8a309bf4dca7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "05db6c7ea0a143eb9527997e95162e42",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f0c697c80d2f48de85772959be121976",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4702d3211c7487bb1ee5d99ef151820",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7635a1487dc449958818f0c3093bf1e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca457e103a95436d876251854804344c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec9642bf2e294aafafbb83b6a784214b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "168cd271d2b042f9a629364d6f912b03",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f0df7d508822473ea713310a0064c5f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6daece750d164b249bb94dfe1cf67c7f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a25d6bd30b3d429f85391bdbbadb3168",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d1f1ce15e8b4d10ab6afae2c5a1e47e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "846233484ba44aa2857bee2ef9ac6731",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a0331f980fec4dc3b4d0ba90e99ba863",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "283834854fda442a87c5e833135a548d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce9e54649a98451495e2cba758eccb27",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad90285db14c4ec0ad8a82b0d983bdfd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae00c34609f148728e4ac59103dd9fc9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "acbc5cc2058b4b4ab4f2beada74d052d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6ea3cfbb1e44de98a05d1a053df5299",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d61ae728308a42a7936268995d5e8255",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe03a3cdcf2345799b625030c1b3ac75",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7113ed5fb48b40fb818f6c7c26936324",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "62e7b95c16bd4c369ce83f144834e5bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c99ec66a0e4146e39542d7352aefd9f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "228eb8f8922740d0927881c72fe212f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14227fa09f6849719786a74c8e231a5e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d738e342279c491fa6b147a426840604",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5397fd2cb76542838bbf8cf76fc117a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6fe8d38894704ea8947a769e82d70716",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "13115c312d6e4a0585f59b348c3bfcff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "46d561334d584d2c93d7e9c585189b3d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3a46f4bff3444dd90d890f26c346e79",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a06c667039f49dba29faf4ced2058f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Chunks vectorized and stored in Chroma.\n"
     ]
    }
   ],
   "source": [
    "# Initialize embedding model\n",
    "embedding_model = SentenceTransformer('paraphrase-multilingual-MiniLM-L12-v2')\n",
    "\n",
    "# Initialize Chroma client\n",
    "client = chromadb.PersistentClient(path=\"./chroma_db\")\n",
    "collection = client.get_or_create_collection(\n",
    "    name=\"rag_corpus\",\n",
    "    embedding_function=embedding_functions.SentenceTransformerEmbeddingFunction(\n",
    "        model_name='paraphrase-multilingual-MiniLM-L12-v2'\n",
    "    )\n",
    ")\n",
    "\n",
    "# Embed and store chunks\n",
    "for i, chunk in enumerate(chunks):\n",
    "    collection.add(\n",
    "        documents=[chunk],\n",
    "        ids=[f\"chunk_{i}\"],\n",
    "        metadatas=[{\"source\": \"HSC26-Bangla1st-Paper.pdf_and_qa_dataset\", \"chunk_id\": i}]\n",
    "    )\n",
    "logger.info(\"Chunks vectorized and stored in Chroma.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "113c9614",
   "metadata": {},
   "source": [
    "### 5: Simulated Fine-Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b044a98b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Simulated fine-tuning context prepared.\n"
     ]
    }
   ],
   "source": [
    "# Simulated fine-tuning: Prepare QA pairs as additional context\n",
    "def prepare_fine_tune_context(qa_texts, max_examples=5):\n",
    "    return '\\n'.join(qa_texts[:max_examples])  # Limit to avoid overwhelming prompt\n",
    "\n",
    "fine_tune_context = prepare_fine_tune_context(qa_texts)\n",
    "logger.info(\"Simulated fine-tuning context prepared.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e55dc9d",
   "metadata": {},
   "source": [
    "### 6: Query Processing and Answer Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9c9e0d74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db848cdee37b48999877bcd6dd4b2dd6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/generate \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: অমর সেনের থিসিসে মূল বিষয় কী বর্ণনা করা হয়েছে?\n",
      "Response:  অমর সেনের থিসিসে বর্ণনা করা হয়েছে, যে তিনি একটি সংজ্ঞাযুলী হিসেবে অপরিচিতা গল্পের মূল প্রtagonist ছিলেন।\n",
      "Retrieved Docs: ['Question: অনুপমের মামা কেন হরিশের সঙ্গে কল্যাণীর বিয়ের প্রস্তাব প্রত্যাখ্যান করেন?', 'Question: ‘অপরিচিতা’ গল্পে রবীন্দ্রনাথ ঠাকুর কোন বিষয়ের পক্ষে বার্তা প্রদান করেছেন?', 'Question: অনুপমের মামা গহনা পরীক্ষার সময় কী বলেন এবং এটি কী প্রকাশ করে?']\n",
      "Scores: [2.1590614318847656, 2.246817111968994, 2.4049301147460938]\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6474b7d38ee3464eb6ea0ec677e3b6b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/generate \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: অনুপম তার জীবনের মূল্য সম্পর্কে কী বলেছেন?\n",
      "Response:  অনুপম বলেছেন, তার জীবন দীর্ঘ বা গুণে হাসাবে নয়, তবে এর একটু বিশেষ মূল্য আছে, যেমন একটি ফুলের মতো যার উপর ভ্রমর এসেছে এবং যার জীবনের মাঝখানে ইতিহাস ফুলের মতো গুটি ধরেছে।\n",
      "Retrieved Docs: ['Answer: উদ্দীপকে পলিশ স্বাধীন মত প্রকাশের সাহস দেখিয়ে বিয়েতে অসম্মতি জানান এবং এর মাধ্যমে তার ব্যক্তিত্বের প্রকাশ ঘটে।', 'Answer: অনুপমের মায়ের অতিরিক্ত স্নেহের ফলে সে একজন ব্যক্তিত্বহীন ও নির্ভরশীল ব্যক্তি হয়ে উঠেছে।', 'Answer: অনুপমের মামা হরিশের সঙ্গে কল্যাণীর বিয়ের প্রস্তাব প্রত্যাখ্যান করেন কারণ তিনি হরিশের যৌতুকপ্রথার প্রতি লোভী মানসিকতা পছন্দ করেননি।']\n",
      "Scores: [2.0259430408477783, 2.44244647026062, 2.634687662124634]\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f981c6deb964739abf79387a7bd8da5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/generate \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: What is the main topic of Amartya Sen's thesis?\n",
      "Response:  The main topic of Amartya Sen's thesis is not explicitly mentioned in the provided context, but it is discussed that he used mathematical modeling for analysis in his work related to climate change and its economic impacts.\n",
      "Retrieved Docs: [\"Amartya Sen's thesis discusses climate change and its economic impacts. He used mathematical modeling for analysis. He received the Nobel Prize in 2018 for his work. Context: আমার বয়স সাতার মাত্র।\", 'Question: Who is the author of the story ‘Aparichita’? Answer: Rabindranath Tagore\\nContext: Kalyani’s father, Shambhunath Sen, worked in the railway department.', 'Answer: রমা যৌতুকের দাবি প্রত্যাখ্যান করে স্বাধীনভাবে নিজের জীবন গড়ার সিদ্ধান্ত নেন। Context: ‘অপরিচিতা’ গল্পে রবীন্দ্রনাথ ঠাকুর নারীর আত্মমর্যাদা ও স্বাধীনতার পক্ষে শক্তিশালী বার্তা প্রদান করেছেন।']\n",
      "Scores: [16.19892120361328, 19.140451431274414, 20.663990020751953]\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bef1850b18d44e90b28f551a6b841dfa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/generate \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: What does Anupam say about the value of his life?\n",
      "Response:  Anupam says his life has special value, like a flower visited by a bee, with history forming like a bud in its life.\n",
      "Retrieved Docs: ['Answer: Anupam says his life is neither long nor full of qualities, but it has a special value, like a flower visited by a bee, with history forming like a bud in its life.', 'It is like a flower on which a bee has landed, and in the middle of whose life history has begun to form like a bud. Question: What does Anupam say about the value of his life?', 'Question: Where did Anupam work? Answer: In a bank\\nContext: Anupam was an honest, educated, and confident suitor, though his mother’s excessive affection made him personality-less.']\n",
      "Scores: [9.333261489868164, 11.786201477050781, 15.223621368408203]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Short-term memory (conversation history)\n",
    "conversation_history = []\n",
    "\n",
    "def process_query(query, max_results=3):\n",
    "    # Embed query\n",
    "    query_embedding = embedding_model.encode(query)\n",
    "    \n",
    "    # Retrieve relevant chunks\n",
    "    results = collection.query(\n",
    "        query_embeddings=[query_embedding],\n",
    "        n_results=max_results\n",
    "    )\n",
    "    \n",
    "    # Extract relevant documents and scores\n",
    "    retrieved_docs = results['documents'][0]\n",
    "    retrieved_scores = results['distances'][0]\n",
    "    context = ' '.join(retrieved_docs)\n",
    "    \n",
    "    # Prepare prompt with fine-tuned context and conversation history\n",
    "    history_prompt = '\\n'.join([f\"User: {h['query']}\\nAssistant: {h['response']}\" for h in conversation_history[-3:]])\n",
    "    prompt = f\"\"\"\n",
    "    Fine-Tuned Context:\n",
    "    {fine_tune_context}\n",
    "    \n",
    "    Retrieved Context:\n",
    "    {context}\n",
    "    \n",
    "    Recent Conversation:\n",
    "    {history_prompt}\n",
    "    \n",
    "    User Query: {query}\n",
    "    \n",
    "    Provide a concise answer based on the context in the same language as the query.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Generate answer using Ollama\n",
    "    try:\n",
    "        response = ollama.generate(model='mistral', prompt=prompt)['response']\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error generating response: {e}\")\n",
    "        response = \"Sorry, I couldn't generate a response.\"\n",
    "    \n",
    "    # Update conversation history\n",
    "    conversation_history.append({\"query\": query, \"response\": response})\n",
    "    \n",
    "    return response, retrieved_docs, retrieved_scores\n",
    "\n",
    "# Test queries\n",
    "test_queries = [\n",
    "    \"অমর সেনের থিসিসে মূল বিষয় কী বর্ণনা করা হয়েছে?\",\n",
    "    \"অনুপম তার জীবনের মূল্য সম্পর্কে কী বলেছেন?\",\n",
    "    \"What is the main topic of Amartya Sen's thesis?\",\n",
    "    \"What does Anupam say about the value of his life?\"\n",
    "]\n",
    "\n",
    "for query in test_queries:\n",
    "    response, docs, scores = process_query(query)\n",
    "    print(f\"Query: {query}\")\n",
    "    print(f\"Response: {response}\")\n",
    "    print(f\"Retrieved Docs: {docs}\")\n",
    "    print(f\"Scores: {scores}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a7ca3c9",
   "metadata": {},
   "source": [
    "### 7: REST API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4a926f40",
   "metadata": {},
   "outputs": [],
   "source": [
    "app = FastAPI(title=\"Multilingual RAG API with QA Dataset\")\n",
    "\n",
    "class QueryRequest(BaseModel):\n",
    "    query: str\n",
    "\n",
    "@app.post(\"/query\")\n",
    "async def query_rag(request: QueryRequest):\n",
    "    try:\n",
    "        response, retrieved_docs, scores = process_query(request.query)\n",
    "        return {\n",
    "            \"query\": request.query,\n",
    "            \"response\": response,\n",
    "            \"retrieved_documents\": retrieved_docs,\n",
    "            \"similarity_scores\": scores\n",
    "        }\n",
    "    except Exception as e:\n",
    "        logger.error(f\"API error: {e}\")\n",
    "        raise HTTPException(status_code=500, detail=str(e))\n",
    "\n",
    "# Run the API (execute in a separate terminal or script)\n",
    "# uvicorn.run(app, host=\"0.0.0.0\", port=8000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0dcbd6a",
   "metadata": {},
   "source": [
    "### 8: RAG Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cda296c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "89c930337b9a4a89bf00611f5e7633e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/generate \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "57ceef3b72924a7fb9e44d54f4f7a7cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a369568f70b4f7bbfc0c0e6c3161a80",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14760ea2f27347bfa1303f2e5442abfb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c1c943cee544e40849847d573f55ef4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: অনুপম তার জীবনের মূল্য সম্পর্কে কী বলেছেন?\n",
      "Response:  Anupam has said that his life has special value, like a flower visited by a bee, with history forming like a bud in its life.\n",
      "Expected: অনুপম বলেছেন যে তার জীবন দীর্ঘ বা গুণে হাসাবে নয়, তবে এর একটু বিশেষ মূল্য আছে, যেমন একটি ফুলের মতো যার উপর ভ্রমর এসেছে এবং যার জীবনের মাঝখানে ইতিহাস ফুলের মতো গুটি ধরেছে।\n",
      "Metrics: {'relevance_score': np.float32(0.90325814), 'groundedness_score': np.float32(0.27362576), 'accuracy': np.float32(0.15280285)}\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9004b3a7808f48478f6bf42a5ba9c0ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/generate \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a80084b79514866b660c7f0a092346d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a484e70e352d4abb80d53a67c7549af5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6391c09420b64de69235c0e36eac13a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31fbbd1b00384ce49e68594d40afb66e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: What does Anupam say about the value of his life?\n",
      "Response:  Anupam says his life has special value, like a flower visited by a bee, with history forming like a bud in its life.\n",
      "Expected: Anupam says his life is neither long nor full of qualities, but it has a special value, like a flower visited by a bee, with history forming like a bud in its life.\n",
      "Metrics: {'relevance_score': np.float32(0.65749913), 'groundedness_score': np.float32(0.7085655), 'accuracy': np.float32(0.92067456)}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def evaluate_rag(query, response, retrieved_docs, expected_answer=None):\n",
    "    # Embed query and response\n",
    "    query_embedding = embedding_model.encode(query)\n",
    "    response_embedding = embedding_model.encode(response)\n",
    "    \n",
    "    # Calculate relevance (query vs retrieved docs)\n",
    "    doc_embeddings = embedding_model.encode(retrieved_docs)\n",
    "    relevance_scores = cosine_similarity([query_embedding], doc_embeddings)[0]\n",
    "    avg_relevance = np.mean(relevance_scores)\n",
    "    \n",
    "    # Calculate groundedness (response vs retrieved docs)\n",
    "    groundedness_scores = cosine_similarity([response_embedding], doc_embeddings)[0]\n",
    "    avg_groundedness = np.mean(groundedness_scores)\n",
    "    \n",
    "    # Calculate accuracy if expected answer is provided\n",
    "    accuracy = None\n",
    "    if expected_answer:\n",
    "        expected_embedding = embedding_model.encode(expected_answer)\n",
    "        accuracy = cosine_similarity([response_embedding], [expected_embedding])[0][0]\n",
    "    \n",
    "    return {\n",
    "        \"relevance_score\": avg_relevance,\n",
    "        \"groundedness_score\": avg_groundedness,\n",
    "        \"accuracy\": accuracy\n",
    "    }\n",
    "\n",
    "# Evaluate test queries with expected answers from QA dataset\n",
    "qa_pairs = load_qa_dataset('bangla_english_qa_dataset.json')\n",
    "test_cases = [\n",
    "    {\"query\": \"অনুপম তার জীবনের মূল্য সম্পর্কে কী বলেছেন?\", \n",
    "     \"expected\": \"অনুপম বলেছেন যে তার জীবন দীর্ঘ বা গুণে হাসাবে নয়, তবে এর একটু বিশেষ মূল্য আছে, যেমন একটি ফুলের মতো যার উপর ভ্রমর এসেছে এবং যার জীবনের মাঝখানে ইতিহাস ফুলের মতো গুটি ধরেছে।\"},\n",
    "    {\"query\": \"What does Anupam say about the value of his life?\", \n",
    "     \"expected\": \"Anupam says his life is neither long nor full of qualities, but it has a special value, like a flower visited by a bee, with history forming like a bud in its life.\"}\n",
    "]\n",
    "\n",
    "for case in test_cases:\n",
    "    response, retrieved_docs, _ = process_query(case['query'])\n",
    "    metrics = evaluate_rag(case['query'], response, retrieved_docs, case['expected'])\n",
    "    print(f\"Query: {case['query']}\")\n",
    "    print(f\"Response: {response}\")\n",
    "    print(f\"Expected: {case['expected']}\")\n",
    "    print(f\"Metrics: {metrics}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7e9ca9b",
   "metadata": {},
   "source": [
    "### 9: Sample Test Case Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5a2e0171",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92068265ef2e414798d34a29afd1632a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/generate \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e341f926bd4045b68d7cdfac24769058",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b4b389f8eea45e9b96bd24328939df8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e74aa1dfa6b4d6fb8235ff1f4373495",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e9afaf5c497449b86c35476a96aa081",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: অনুপমের ভাষায় সুপুরুষ কাকে বলা হয়েছে?\n",
      "Response:  অনুপমের ভাষায় এই মতারমত বলা হয়েছিল, 'একজন সুপুরুষ কাকে আমি বলতে চাই'।\n",
      "(Based on the context: \"Anupam has said that he wants to call someone a supurush.\")\n",
      "Expected Answer: শুম্ভুনাথ\n",
      "Metrics: {'relevance_score': np.float32(0.9030021), 'groundedness_score': np.float32(0.5454555), 'accuracy': np.float32(0.48164445)}\n",
      "Retrieved Documents: ['Answer: উদ্দীপকে পলিশ স্বাধীন মত প্রকাশের সাহস দেখিয়ে বিয়েতে অসম্মতি জানান এবং এর মাধ্যমে তার ব্যক্তিত্বের প্রকাশ ঘটে।', 'Answer: অনুপমের মায়ের অতিরিক্ত স্নেহের ফলে সে একজন ব্যক্তিত্বহীন ও নির্ভরশীল ব্যক্তি হয়ে উঠেছে।', 'Answer: অনুপমের মামা হরিশের সঙ্গে কল্যাণীর বিয়ের প্রস্তাব প্রত্যাখ্যান করেন কারণ তিনি হরিশের যৌতুকপ্রথার প্রতি লোভী মানসিকতা পছন্দ করেননি।']\n",
      "Similarity Scores: [2.020740032196045, 2.261037826538086, 2.5281548500061035]\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "83c9a6621f0d4477a2484ca033d7c6cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/generate \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07a5e6c4a64a49d5b977e8843dbc1949",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "08a7d1cfefde4960889dd7624348938d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47da6fc868ea4615b6b845fa7d4a85b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4aacd2d569304decb477ae0a3794517f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: কাকে অনুপমের ভাগ্যদেবতা বলে উল্লেখ করা হয়েছে?\n",
      "Response:  অনুপমের ভাগ্যদেবতা বলে উল্লেখ করা হয়েছে সার্বজনিন আব্জীত ভূমিপুরীর বৈঠক্যে।\n",
      "(Based on the context: \"Anupam's fate has been referred to as Sovereign Ajit Vohra in a meeting with Sarvajanin Abhijit BhumiPuri.\")\n",
      "Expected Answer: মামাকে\n",
      "Metrics: {'relevance_score': np.float32(0.9308326), 'groundedness_score': np.float32(0.38387933), 'accuracy': np.float32(0.37980494)}\n",
      "Retrieved Documents: ['Question: অনুপমের মামা কেন হরিশের সঙ্গে কল্যাণীর বিয়ের প্রস্তাব প্রত্যাখ্যান করেন?', 'Question: অনুপমের মামা গহনা পরীক্ষার সময় কী বলেন এবং এটি কী প্রকাশ করে?', 'Answer: উদ্দীপকে পলিশ স্বাধীন মত প্রকাশের সাহস দেখিয়ে বিয়েতে অসম্মতি জানান এবং এর মাধ্যমে তার ব্যক্তিত্বের প্রকাশ ঘটে।']\n",
      "Similarity Scores: [2.1366825103759766, 2.274994373321533, 2.3612942695617676]\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4b7248e769b49ae846093f573b2897a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/generate \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b9174d7ac6fe4b939647f780a1f23aa9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "35b76702023f4c1d9df84207058d68ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15915477012a48fb93642e84e7b7b517",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "77dee1bbed8046da8b604c5a6d8b354b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: বিয়ের সময় কল্যাণীর প্রকৃত বয়স কত ছিল?\n",
      "Response:  কল্যাণীর প্রকৃত বয়সটা দেখানো হয়নি।\n",
      "Expected Answer: ১৫ বছর\n",
      "Metrics: {'relevance_score': np.float32(0.87211365), 'groundedness_score': np.float32(0.4458154), 'accuracy': np.float32(0.445535)}\n",
      "Retrieved Documents: ['Answer: উদ্দীপকে পলিশ স্বাধীন মত প্রকাশের সাহস দেখিয়ে বিয়েতে অসম্মতি জানান এবং এর মাধ্যমে তার ব্যক্তিত্বের প্রকাশ ঘটে।', 'Question: অনুপমের মামা কেন হরিশের সঙ্গে কল্যাণীর বিয়ের প্রস্তাব প্রত্যাখ্যান করেন?', 'Answer: অনুপমের মায়ের অতিরিক্ত স্নেহের ফলে সে একজন ব্যক্তিত্বহীন ও নির্ভরশীল ব্যক্তি হয়ে উঠেছে।']\n",
      "Similarity Scores: [3.0673365592956543, 3.310023069381714, 3.5558202266693115]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Define sample test cases\n",
    "sample_test_cases = [\n",
    "    {\n",
    "        \"query\": \"অনুপমের ভাষায় সুপুরুষ কাকে বলা হয়েছে?\",\n",
    "        \"expected\": \"শুম্ভুনাথ\"\n",
    "    },\n",
    "    {\n",
    "        \"query\": \"কাকে অনুপমের ভাগ্যদেবতা বলে উল্লেখ করা হয়েছে?\",\n",
    "        \"expected\": \"মামাকে\"\n",
    "    },\n",
    "    {\n",
    "        \"query\": \"বিয়ের সময় কল্যাণীর প্রকৃত বয়স কত ছিল?\",\n",
    "        \"expected\": \"১৫ বছর\"\n",
    "    }\n",
    "]\n",
    "\n",
    "# Evaluate each test case\n",
    "for case in sample_test_cases:\n",
    "    # Process query\n",
    "    response, retrieved_docs, scores = process_query(case['query'])\n",
    "    \n",
    "    # Evaluate metrics\n",
    "    metrics = evaluate_rag(case['query'], response, retrieved_docs, case['expected'])\n",
    "    \n",
    "    # Log results\n",
    "    print(f\"Query: {case['query']}\")\n",
    "    print(f\"Response: {response}\")\n",
    "    print(f\"Expected Answer: {case['expected']}\")\n",
    "    print(f\"Metrics: {metrics}\")\n",
    "    print(f\"Retrieved Documents: {retrieved_docs}\")\n",
    "    print(f\"Similarity Scores: {scores}\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RAG Fine-Tune",
   "language": "python",
   "name": "rag_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
