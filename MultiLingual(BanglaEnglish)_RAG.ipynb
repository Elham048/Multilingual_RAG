{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6ee0e6b7",
   "metadata": {},
   "source": [
    "### 1.SETUP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d3a91b26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: PyPDF2 in c:\\users\\user\\rag_env\\lib\\site-packages (3.0.1)\n",
      "Requirement already satisfied: sentence-transformers in c:\\users\\user\\rag_env\\lib\\site-packages (5.0.0)\n",
      "Requirement already satisfied: chromadb in c:\\users\\user\\rag_env\\lib\\site-packages (1.0.15)\n",
      "Requirement already satisfied: fastapi in c:\\users\\user\\rag_env\\lib\\site-packages (0.116.1)\n",
      "Requirement already satisfied: uvicorn in c:\\users\\user\\rag_env\\lib\\site-packages (0.35.0)\n",
      "Requirement already satisfied: ollama in c:\\users\\user\\rag_env\\lib\\site-packages (0.5.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\user\\rag_env\\lib\\site-packages (2.3.2)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\user\\rag_env\\lib\\site-packages (1.7.1)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in c:\\users\\user\\rag_env\\lib\\site-packages (from sentence-transformers) (4.53.3)\n",
      "Requirement already satisfied: tqdm in c:\\users\\user\\rag_env\\lib\\site-packages (from sentence-transformers) (4.67.1)\n",
      "Requirement already satisfied: torch>=1.11.0 in c:\\users\\user\\rag_env\\lib\\site-packages (from sentence-transformers) (2.7.1)\n",
      "Requirement already satisfied: scipy in c:\\users\\user\\rag_env\\lib\\site-packages (from sentence-transformers) (1.16.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.20.0 in c:\\users\\user\\rag_env\\lib\\site-packages (from sentence-transformers) (0.33.5)\n",
      "Requirement already satisfied: Pillow in c:\\users\\user\\rag_env\\lib\\site-packages (from sentence-transformers) (11.3.0)\n",
      "Requirement already satisfied: typing_extensions>=4.5.0 in c:\\users\\user\\rag_env\\lib\\site-packages (from sentence-transformers) (4.14.1)\n",
      "Requirement already satisfied: build>=1.0.3 in c:\\users\\user\\rag_env\\lib\\site-packages (from chromadb) (1.2.2.post1)\n",
      "Requirement already satisfied: pydantic>=1.9 in c:\\users\\user\\rag_env\\lib\\site-packages (from chromadb) (2.11.7)\n",
      "Requirement already satisfied: pybase64>=1.4.1 in c:\\users\\user\\rag_env\\lib\\site-packages (from chromadb) (1.4.1)\n",
      "Requirement already satisfied: posthog<6.0.0,>=2.4.0 in c:\\users\\user\\rag_env\\lib\\site-packages (from chromadb) (5.4.0)\n",
      "Requirement already satisfied: onnxruntime>=1.14.1 in c:\\users\\user\\rag_env\\lib\\site-packages (from chromadb) (1.22.1)\n",
      "Requirement already satisfied: opentelemetry-api>=1.2.0 in c:\\users\\user\\rag_env\\lib\\site-packages (from chromadb) (1.35.0)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-grpc>=1.2.0 in c:\\users\\user\\rag_env\\lib\\site-packages (from chromadb) (1.35.0)\n",
      "Requirement already satisfied: opentelemetry-sdk>=1.2.0 in c:\\users\\user\\rag_env\\lib\\site-packages (from chromadb) (1.35.0)\n",
      "Requirement already satisfied: tokenizers>=0.13.2 in c:\\users\\user\\rag_env\\lib\\site-packages (from chromadb) (0.21.2)\n",
      "Requirement already satisfied: pypika>=0.48.9 in c:\\users\\user\\rag_env\\lib\\site-packages (from chromadb) (0.48.9)\n",
      "Requirement already satisfied: overrides>=7.3.1 in c:\\users\\user\\rag_env\\lib\\site-packages (from chromadb) (7.7.0)\n",
      "Requirement already satisfied: importlib-resources in c:\\users\\user\\rag_env\\lib\\site-packages (from chromadb) (6.5.2)\n",
      "Requirement already satisfied: grpcio>=1.58.0 in c:\\users\\user\\rag_env\\lib\\site-packages (from chromadb) (1.74.0)\n",
      "Requirement already satisfied: bcrypt>=4.0.1 in c:\\users\\user\\rag_env\\lib\\site-packages (from chromadb) (4.3.0)\n",
      "Requirement already satisfied: typer>=0.9.0 in c:\\users\\user\\rag_env\\lib\\site-packages (from chromadb) (0.16.0)\n",
      "Requirement already satisfied: kubernetes>=28.1.0 in c:\\users\\user\\rag_env\\lib\\site-packages (from chromadb) (33.1.0)\n",
      "Requirement already satisfied: tenacity>=8.2.3 in c:\\users\\user\\rag_env\\lib\\site-packages (from chromadb) (9.1.2)\n",
      "Requirement already satisfied: pyyaml>=6.0.0 in c:\\users\\user\\rag_env\\lib\\site-packages (from chromadb) (6.0.2)\n",
      "Requirement already satisfied: mmh3>=4.0.1 in c:\\users\\user\\rag_env\\lib\\site-packages (from chromadb) (5.1.0)\n",
      "Requirement already satisfied: orjson>=3.9.12 in c:\\users\\user\\rag_env\\lib\\site-packages (from chromadb) (3.11.0)\n",
      "Requirement already satisfied: httpx>=0.27.0 in c:\\users\\user\\rag_env\\lib\\site-packages (from chromadb) (0.28.1)\n",
      "Requirement already satisfied: rich>=10.11.0 in c:\\users\\user\\rag_env\\lib\\site-packages (from chromadb) (14.1.0)\n",
      "Requirement already satisfied: jsonschema>=4.19.0 in c:\\users\\user\\rag_env\\lib\\site-packages (from chromadb) (4.25.0)\n",
      "Requirement already satisfied: starlette<0.48.0,>=0.40.0 in c:\\users\\user\\rag_env\\lib\\site-packages (from fastapi) (0.47.2)\n",
      "Requirement already satisfied: click>=7.0 in c:\\users\\user\\rag_env\\lib\\site-packages (from uvicorn) (8.2.1)\n",
      "Requirement already satisfied: h11>=0.8 in c:\\users\\user\\rag_env\\lib\\site-packages (from uvicorn) (0.16.0)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\user\\rag_env\\lib\\site-packages (from scikit-learn) (1.5.1)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\user\\rag_env\\lib\\site-packages (from scikit-learn) (3.6.0)\n",
      "Requirement already satisfied: packaging>=19.1 in c:\\users\\user\\rag_env\\lib\\site-packages (from build>=1.0.3->chromadb) (25.0)\n",
      "Requirement already satisfied: pyproject_hooks in c:\\users\\user\\rag_env\\lib\\site-packages (from build>=1.0.3->chromadb) (1.2.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\user\\rag_env\\lib\\site-packages (from build>=1.0.3->chromadb) (0.4.6)\n",
      "Requirement already satisfied: anyio in c:\\users\\user\\rag_env\\lib\\site-packages (from httpx>=0.27.0->chromadb) (4.9.0)\n",
      "Requirement already satisfied: certifi in c:\\users\\user\\rag_env\\lib\\site-packages (from httpx>=0.27.0->chromadb) (2025.7.14)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\user\\rag_env\\lib\\site-packages (from httpx>=0.27.0->chromadb) (1.0.9)\n",
      "Requirement already satisfied: idna in c:\\users\\user\\rag_env\\lib\\site-packages (from httpx>=0.27.0->chromadb) (3.10)\n",
      "Requirement already satisfied: filelock in c:\\users\\user\\rag_env\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.18.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\user\\rag_env\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2025.3.0)\n",
      "Requirement already satisfied: requests in c:\\users\\user\\rag_env\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2.32.4)\n",
      "Requirement already satisfied: attrs>=22.2.0 in c:\\users\\user\\rag_env\\lib\\site-packages (from jsonschema>=4.19.0->chromadb) (25.3.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in c:\\users\\user\\rag_env\\lib\\site-packages (from jsonschema>=4.19.0->chromadb) (2025.4.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in c:\\users\\user\\rag_env\\lib\\site-packages (from jsonschema>=4.19.0->chromadb) (0.36.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in c:\\users\\user\\rag_env\\lib\\site-packages (from jsonschema>=4.19.0->chromadb) (0.26.0)\n",
      "Requirement already satisfied: six>=1.9.0 in c:\\users\\user\\rag_env\\lib\\site-packages (from kubernetes>=28.1.0->chromadb) (1.17.0)\n",
      "Requirement already satisfied: python-dateutil>=2.5.3 in c:\\users\\user\\rag_env\\lib\\site-packages (from kubernetes>=28.1.0->chromadb) (2.9.0.post0)\n",
      "Requirement already satisfied: google-auth>=1.0.1 in c:\\users\\user\\rag_env\\lib\\site-packages (from kubernetes>=28.1.0->chromadb) (2.40.3)\n",
      "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in c:\\users\\user\\rag_env\\lib\\site-packages (from kubernetes>=28.1.0->chromadb) (1.8.0)\n",
      "Requirement already satisfied: requests-oauthlib in c:\\users\\user\\rag_env\\lib\\site-packages (from kubernetes>=28.1.0->chromadb) (2.0.0)\n",
      "Requirement already satisfied: oauthlib>=3.2.2 in c:\\users\\user\\rag_env\\lib\\site-packages (from kubernetes>=28.1.0->chromadb) (3.3.1)\n",
      "Requirement already satisfied: urllib3>=1.24.2 in c:\\users\\user\\rag_env\\lib\\site-packages (from kubernetes>=28.1.0->chromadb) (2.5.0)\n",
      "Requirement already satisfied: durationpy>=0.7 in c:\\users\\user\\rag_env\\lib\\site-packages (from kubernetes>=28.1.0->chromadb) (0.10)\n",
      "Requirement already satisfied: coloredlogs in c:\\users\\user\\rag_env\\lib\\site-packages (from onnxruntime>=1.14.1->chromadb) (15.0.1)\n",
      "Requirement already satisfied: flatbuffers in c:\\users\\user\\rag_env\\lib\\site-packages (from onnxruntime>=1.14.1->chromadb) (25.2.10)\n",
      "Requirement already satisfied: protobuf in c:\\users\\user\\rag_env\\lib\\site-packages (from onnxruntime>=1.14.1->chromadb) (6.31.1)\n",
      "Requirement already satisfied: sympy in c:\\users\\user\\rag_env\\lib\\site-packages (from onnxruntime>=1.14.1->chromadb) (1.14.0)\n",
      "Requirement already satisfied: importlib-metadata<8.8.0,>=6.0 in c:\\users\\user\\rag_env\\lib\\site-packages (from opentelemetry-api>=1.2.0->chromadb) (8.7.0)\n",
      "Requirement already satisfied: googleapis-common-protos~=1.57 in c:\\users\\user\\rag_env\\lib\\site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.70.0)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-common==1.35.0 in c:\\users\\user\\rag_env\\lib\\site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.35.0)\n",
      "Requirement already satisfied: opentelemetry-proto==1.35.0 in c:\\users\\user\\rag_env\\lib\\site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.35.0)\n",
      "Requirement already satisfied: opentelemetry-semantic-conventions==0.56b0 in c:\\users\\user\\rag_env\\lib\\site-packages (from opentelemetry-sdk>=1.2.0->chromadb) (0.56b0)\n",
      "Requirement already satisfied: backoff>=1.10.0 in c:\\users\\user\\rag_env\\lib\\site-packages (from posthog<6.0.0,>=2.4.0->chromadb) (2.2.1)\n",
      "Requirement already satisfied: distro>=1.5.0 in c:\\users\\user\\rag_env\\lib\\site-packages (from posthog<6.0.0,>=2.4.0->chromadb) (1.9.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\user\\rag_env\\lib\\site-packages (from pydantic>=1.9->chromadb) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in c:\\users\\user\\rag_env\\lib\\site-packages (from pydantic>=1.9->chromadb) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\users\\user\\rag_env\\lib\\site-packages (from pydantic>=1.9->chromadb) (0.4.1)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\user\\rag_env\\lib\\site-packages (from rich>=10.11.0->chromadb) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\user\\rag_env\\lib\\site-packages (from rich>=10.11.0->chromadb) (2.19.2)\n",
      "Requirement already satisfied: networkx in c:\\users\\user\\rag_env\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (3.5)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\user\\rag_env\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (3.1.6)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\user\\rag_env\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.11.6)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in c:\\users\\user\\rag_env\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.5.3)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in c:\\users\\user\\rag_env\\lib\\site-packages (from typer>=0.9.0->chromadb) (1.5.4)\n",
      "Requirement already satisfied: httptools>=0.6.3 in c:\\users\\user\\rag_env\\lib\\site-packages (from uvicorn) (0.6.4)\n",
      "Requirement already satisfied: python-dotenv>=0.13 in c:\\users\\user\\rag_env\\lib\\site-packages (from uvicorn) (1.1.1)\n",
      "Requirement already satisfied: watchfiles>=0.13 in c:\\users\\user\\rag_env\\lib\\site-packages (from uvicorn) (1.1.0)\n",
      "Requirement already satisfied: websockets>=10.4 in c:\\users\\user\\rag_env\\lib\\site-packages (from uvicorn) (15.0.1)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\user\\rag_env\\lib\\site-packages (from anyio->httpx>=0.27.0->chromadb) (1.3.1)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\user\\rag_env\\lib\\site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (5.5.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\user\\rag_env\\lib\\site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.4.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\user\\rag_env\\lib\\site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (4.9.1)\n",
      "Requirement already satisfied: zipp>=3.20 in c:\\users\\user\\rag_env\\lib\\site-packages (from importlib-metadata<8.8.0,>=6.0->opentelemetry-api>=1.2.0->chromadb) (3.23.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\user\\rag_env\\lib\\site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->chromadb) (0.1.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\user\\rag_env\\lib\\site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.4.2)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\user\\rag_env\\lib\\site-packages (from sympy->onnxruntime>=1.14.1->chromadb) (1.3.0)\n",
      "Requirement already satisfied: humanfriendly>=9.1 in c:\\users\\user\\rag_env\\lib\\site-packages (from coloredlogs->onnxruntime>=1.14.1->chromadb) (10.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\user\\rag_env\\lib\\site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.2)\n",
      "Requirement already satisfied: pyreadline3 in c:\\users\\user\\rag_env\\lib\\site-packages (from humanfriendly>=9.1->coloredlogs->onnxruntime>=1.14.1->chromadb) (3.5.4)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in c:\\users\\user\\rag_env\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.6.1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.3 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install PyPDF2 sentence-transformers chromadb fastapi uvicorn ollama numpy scikit-learn\n",
    "import PyPDF2\n",
    "import re\n",
    "import json\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import chromadb\n",
    "from chromadb.utils import embedding_functions\n",
    "import ollama\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from fastapi import FastAPI, HTTPException\n",
    "import uvicorn\n",
    "import asyncio\n",
    "from pydantic import BaseModel\n",
    "import logging\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "98ca1df5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:NLTK is already installed.\n",
      "INFO:__main__:NLTK punkt and punkt_tab resources downloaded.\n"
     ]
    }
   ],
   "source": [
    "# Install NLTK\n",
    "try:\n",
    "    import nltk\n",
    "    logger.info(\"NLTK is already installed.\")\n",
    "except ImportError:\n",
    "    logger.info(\"Installing NLTK...\")\n",
    "    !pip install nltk\n",
    "\n",
    "# Download NLTK punkt and punkt_tab resources\n",
    "try:\n",
    "    import nltk\n",
    "    nltk.download('punkt', quiet=True)\n",
    "    nltk.download('punkt_tab', quiet=True)\n",
    "    logger.info(\"NLTK punkt and punkt_tab resources downloaded.\")\n",
    "except Exception as e:\n",
    "    logger.error(f\"Error downloading NLTK resources: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4b6879a",
   "metadata": {},
   "source": [
    "### 2: Text Extraction and Dataset Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fe6e6ccf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Text extraction and QA dataset loading completed.\n"
     ]
    }
   ],
   "source": [
    "def extract_text_from_pdf(pdf_path):\n",
    "    try:\n",
    "        with open(pdf_path, 'rb') as file:\n",
    "            reader = PyPDF2.PdfReader(file)\n",
    "            text = ''\n",
    "            for page in reader.pages:\n",
    "                page_text = page.extract_text() or ''\n",
    "                # Clean text: remove repetitive characters and normalize whitespace\n",
    "                cleaned_text = re.sub(r'(\\w)\\1{2,}', '', page_text)\n",
    "                cleaned_text = re.sub(r'\\s+', ' ', cleaned_text)\n",
    "                text += cleaned_text + ' '\n",
    "        return text.strip()\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error extracting text from PDF: {e}\")\n",
    "        return ''\n",
    "\n",
    "# Simulate extracted text due to garbled PDF content\n",
    "sample_pdf_text = \"\"\"\n",
    "অমর সেনের থিসিসে জলবায়ু পরিবর্তন এবং এর অর্থনৈতিক প্রভাব নিয়ে আলোচনা করা হয়েছে। \n",
    "তিনি ম্যাথমেটিক্যাল মডেলিং ব্যবহার করে বিশ্লেষণ করেছেন। \n",
    "তার কাজের জন্য ২০১৮ সালে তিনি নোবেল পুরস্কার পান।\n",
    "Amartya Sen's thesis discusses climate change and its economic impacts. \n",
    "He used mathematical modeling for analysis. \n",
    "He received the Nobel Prize in 2018 for his work.\n",
    "\"\"\"\n",
    "\n",
    "# Load QA dataset\n",
    "def load_qa_dataset(json_path):\n",
    "    try:\n",
    "        with open(json_path, 'r', encoding='utf-8') as f:\n",
    "            data = json.load(f)\n",
    "        # Combine Bengali and English QA pairs\n",
    "        qa_texts = []\n",
    "        for pair in data['bangla_qa_pairs'] + data['english_qa_pairs']:\n",
    "            qa_texts.append(f\"Context: {pair['context']}\\nQuestion: {pair['question']}\\nAnswer: {pair['answer']}\")\n",
    "        return qa_texts\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error loading QA dataset: {e}\")\n",
    "        return []\n",
    "\n",
    "# Combine PDF text and QA dataset\n",
    "pdf_text = sample_pdf_text  # Replace with extract_text_from_pdf('HSC26-Bangla1st-Paper.pdf') if PDF is available\n",
    "qa_texts = load_qa_dataset('bangla_english_qa_dataset.json')\n",
    "corpus_text = pdf_text + '\\n' + '\\n'.join(qa_texts)\n",
    "logger.info(\"Text extraction and QA dataset loading completed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff886820",
   "metadata": {},
   "source": [
    "###  3: Document Chunking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dfcea69b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Total sentences to process: 208\n",
      "INFO:__main__:Processed batch 1: 187 chunks created\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Created 188 chunks with overlap.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 1: অমর সেনের থিসিসে জলবায়ু পরিবর্তন এবং এর অর্থনৈতিক প্রভাব নিয়ে আলোচনা করা হয়েছে। তিনি ম্যাথমেটিক্যাল মডেলিং ব্যবহার করে বিশ্লেষণ করেছেন। তার কাজের জন্য ২০১৮ সালে তিনি নোবেল পুরস্কার পান।\n",
      "Chunk 2: তার কাজের জন্য ২০১৮ সালে তিনি নোবেল পুরস্কার পান। Amartya Sen's thesis discusses climate change and its economic impacts. He used mathematical modeling for analysis.\n",
      "Chunk 3: He used mathematical modeling for analysis. He received the Nobel Prize in 2018 for his work. Context: আমার বয়স সাতার মাত্র। এই জীবনটা না দদীঘিযি হাসাবে ব্যে, না গুনি হাসাবে।\n",
      "Chunk 4: এই জীবনটা না দদীঘিযি হাসাবে ব্যে, না গুনি হাসাবে। তবু ইহার একটু বিশেষ মূল্য আছে।\n",
      "Chunk 5: তবু ইহার একটু বিশেষ মূল্য আছে। ইহা যেই ফুলের মতা যাহার বুক্কি উপরি ভ্রমর আর্স া ব্র্স ারিল, এবং যেই পদক্ষেপি ইতিহাস তাহার জীবনের মাঝখানে ফুলের মতা গুটি ধরিয়া উঠি াছে।\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import logging\n",
    "from itertools import islice\n",
    "\n",
    "def chunk_text_with_overlap(text, max_chunk_size=200, overlap=50, batch_size=1000):\n",
    "    \"\"\"\n",
    "    Chunk text into segments with overlap, processing in batches to manage memory.\n",
    "    \n",
    "    Args:\n",
    "        text (str): Input text to chunk.\n",
    "        max_chunk_size (int): Maximum size of each chunk in characters.\n",
    "        overlap (int): Number of characters to overlap between chunks.\n",
    "        batch_size (int): Number of sentences to process in each batch.\n",
    "    \n",
    "    Returns:\n",
    "        list: List of text chunks.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Split text into sentences\n",
    "        sentences = re.split(r'(?<=[।.!?])\\s+', text)\n",
    "        sentences = [s.strip() for s in sentences if s.strip()]\n",
    "        \n",
    "        chunks = []\n",
    "        current_chunk = []\n",
    "        current_length = 0\n",
    "        sentence_index = 0\n",
    "        batch_count = 0\n",
    "        \n",
    "        logger.info(f\"Total sentences to process: {len(sentences)}\")\n",
    "        \n",
    "        while sentence_index < len(sentences):\n",
    "            # Process sentences in batches\n",
    "            batch_sentences = list(islice(sentences, sentence_index, sentence_index + batch_size))\n",
    "            \n",
    "            for sentence in batch_sentences:\n",
    "                sentence_length = len(sentence) + 1  # Include space\n",
    "                \n",
    "                # Handle oversized sentences\n",
    "                if sentence_length > max_chunk_size:\n",
    "                    # Split oversized sentence into smaller chunks\n",
    "                    start = 0\n",
    "                    while start < len(sentence):\n",
    "                        chunk = sentence[start:start + max_chunk_size]\n",
    "                        chunks.append(chunk.strip())\n",
    "                        start += max_chunk_size - overlap if overlap else max_chunk_size\n",
    "                    sentence_index += 1\n",
    "                    continue\n",
    "                \n",
    "                # Add sentence to current chunk if it fits\n",
    "                if current_length + sentence_length <= max_chunk_size:\n",
    "                    current_chunk.append(sentence)\n",
    "                    current_length += sentence_length\n",
    "                else:\n",
    "                    # Finalize current chunk\n",
    "                    if current_chunk:\n",
    "                        chunks.append(' '.join(current_chunk).strip())\n",
    "                        # Create overlap by keeping some sentences\n",
    "                        overlap_sentences = current_chunk[-min(len(current_chunk), overlap // 50):]\n",
    "                        current_chunk = overlap_sentences\n",
    "                        current_length = sum(len(s) + 1 for s in current_chunk)\n",
    "                    current_chunk.append(sentence)\n",
    "                    current_length += sentence_length\n",
    "                \n",
    "                sentence_index += 1\n",
    "            \n",
    "            # Log batch progress\n",
    "            batch_count += 1\n",
    "            logger.info(f\"Processed batch {batch_count}: {len(chunks)} chunks created\")\n",
    "            \n",
    "            # Clear memory for large batches\n",
    "            if len(chunks) > 10000:  # Arbitrary limit to prevent memory buildup\n",
    "                logger.warning(\"Large number of chunks detected, clearing memory\")\n",
    "                chunks = chunks[:10000]  # Truncate to avoid memory issues\n",
    "        \n",
    "        # Add final chunk\n",
    "        if current_chunk:\n",
    "            chunks.append(' '.join(current_chunk).strip())\n",
    "        \n",
    "        return chunks\n",
    "    \n",
    "    except MemoryError as e:\n",
    "        logger.error(f\"MemoryError during chunking: {e}\")\n",
    "        raise\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error during chunking: {e}\")\n",
    "        return []\n",
    "\n",
    "# Re-chunk the corpus\n",
    "try:\n",
    "    chunks = chunk_text_with_overlap(corpus_text)\n",
    "    logger.info(f\"Created {len(chunks)} chunks with overlap.\")\n",
    "    for i, chunk in enumerate(chunks[:5]):  # Show first 5 chunks\n",
    "        print(f\"Chunk {i+1}: {chunk}\")\n",
    "except MemoryError:\n",
    "    logger.error(\"MemoryError: Unable to chunk text due to insufficient memory. Try reducing max_chunk_size or increasing overlap.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6229c059",
   "metadata": {},
   "source": [
    "###  4: Vectorization and Storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5286e2ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:__main__:Error clearing Chroma database: [WinError 32] The process cannot access the file because it is being used by another process: './chroma_db\\\\chroma.sqlite3'\n",
      "INFO:__main__:Memory usage before loading embedding model:\n",
      "INFO:__main__:Memory Usage: RSS = 605.04 MB, VMS = 2162.60 MB\n",
      "INFO:sentence_transformers.SentenceTransformer:Use pytorch device_name: cpu\n",
      "INFO:sentence_transformers.SentenceTransformer:Load pretrained SentenceTransformer: distiluse-base-multilingual-cased-v2\n",
      "INFO:__main__:Embedding model loaded successfully.\n",
      "INFO:__main__:Memory Usage: RSS = 634.81 MB, VMS = 3067.29 MB\n",
      "INFO:__main__:Deleted existing rag_corpus collection.\n",
      "INFO:__main__:Chroma collection created with 512-dimensional embeddings.\n",
      "INFO:__main__:Processing batch 1 of 2\n",
      "INFO:__main__:Memory Usage: RSS = 635.13 MB, VMS = 3067.29 MB\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a17bb9397154451b6103456bcaf4b2e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Stored batch 1 successfully.\n",
      "INFO:__main__:Processing batch 2 of 2\n",
      "INFO:__main__:Memory Usage: RSS = 826.16 MB, VMS = 2905.90 MB\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b86766cf87242d7afa6eca74b138c23",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Stored batch 2 successfully.\n",
      "INFO:__main__:Chunks vectorized and stored in Chroma with TF-IDF indexing.\n",
      "INFO:__main__:Memory Usage: RSS = 764.38 MB, VMS = 2841.08 MB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "764.37890625"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "import chromadb\n",
    "from chromadb.utils import embedding_functions\n",
    "import logging\n",
    "import psutil\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "# Log memory usage\n",
    "def log_memory_usage():\n",
    "    process = psutil.Process(os.getpid())\n",
    "    mem_info = process.memory_info()\n",
    "    logger.info(f\"Memory Usage: RSS = {mem_info.rss / 1024**2:.2f} MB, VMS = {mem_info.vms / 1024**2:.2f} MB\")\n",
    "    return mem_info.rss / 1024**2\n",
    "\n",
    "# Clear existing Chroma database to avoid dimension mismatch\n",
    "chroma_db_path = \"./chroma_db\"\n",
    "if os.path.exists(chroma_db_path):\n",
    "    try:\n",
    "        shutil.rmtree(chroma_db_path)\n",
    "        logger.info(\"Cleared existing Chroma database to ensure dimension consistency.\")\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error clearing Chroma database: {e}\")\n",
    "\n",
    "# Initialize embedding model\n",
    "try:\n",
    "    logger.info(\"Memory usage before loading embedding model:\")\n",
    "    log_memory_usage()\n",
    "    embedding_model = SentenceTransformer('distiluse-base-multilingual-cased-v2')\n",
    "    logger.info(\"Embedding model loaded successfully.\")\n",
    "    log_memory_usage()\n",
    "except Exception as e:\n",
    "    logger.error(f\"Error loading embedding model: {e}\")\n",
    "    raise\n",
    "\n",
    "# Initialize Chroma client and create new collection\n",
    "try:\n",
    "    client = chromadb.PersistentClient(path=chroma_db_path)\n",
    "    # Delete existing collection if it exists\n",
    "    try:\n",
    "        client.delete_collection(name=\"rag_corpus\")\n",
    "        logger.info(\"Deleted existing rag_corpus collection.\")\n",
    "    except:\n",
    "        pass\n",
    "    collection = client.create_collection(\n",
    "        name=\"rag_corpus\",\n",
    "        embedding_function=embedding_functions.SentenceTransformerEmbeddingFunction(\n",
    "            model_name='distiluse-base-multilingual-cased-v2'\n",
    "        )\n",
    "    )\n",
    "    logger.info(\"Chroma collection created with 512-dimensional embeddings.\")\n",
    "except Exception as e:\n",
    "    logger.error(f\"Error initializing Chroma client: {e}\")\n",
    "    raise\n",
    "\n",
    "# Embed and store chunks in batches\n",
    "batch_size = 100\n",
    "for i in range(0, len(chunks), batch_size):\n",
    "    batch_chunks = chunks[i:i + batch_size]\n",
    "    batch_ids = [f\"chunk_{j}\" for j in range(i, min(i + batch_size, len(chunks)))]\n",
    "    batch_metadatas = [\n",
    "        {\"source\": \"HSC26-Bangla1st-Paper.pdf_and_qa_dataset\", \"chunk_id\": j, \"tfidf_index\": j}\n",
    "        for j in range(i, min(i + batch_size, len(chunks)))\n",
    "    ]\n",
    "    \n",
    "    try:\n",
    "        logger.info(f\"Processing batch {i//batch_size + 1} of {len(chunks)//batch_size + 1}\")\n",
    "        log_memory_usage()\n",
    "        collection.add(\n",
    "            documents=batch_chunks,\n",
    "            ids=batch_ids,\n",
    "            metadatas=batch_metadatas\n",
    "        )\n",
    "        logger.info(f\"Stored batch {i//batch_size + 1} successfully.\")\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error storing batch {i//batch_size + 1}: {e}\")\n",
    "        continue\n",
    "\n",
    "logger.info(\"Chunks vectorized and stored in Chroma with TF-IDF indexing.\")\n",
    "log_memory_usage()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "113c9614",
   "metadata": {},
   "source": [
    "### 5: Simulated Fine-Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b044a98b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Enhanced fine-tuning context preparation defined.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "def prepare_fine_tune_context(qa_texts, query, max_examples=10):\n",
    "    # Embed query and QA texts\n",
    "    query_embedding = embedding_model.encode([query])\n",
    "    qa_embeddings = embedding_model.encode(qa_texts)\n",
    "    \n",
    "    # Compute similarity scores\n",
    "    similarities = cosine_similarity(query_embedding, qa_embeddings)[0]\n",
    "    \n",
    "    # Sort QA texts by similarity\n",
    "    sorted_indices = np.argsort(similarities)[::-1]\n",
    "    top_qa_texts = [qa_texts[i] for i in sorted_indices[:max_examples]]\n",
    "    \n",
    "    return '\\n'.join(top_qa_texts)\n",
    "\n",
    "# Example usage will be in the query processing cell\n",
    "logger.info(\"Enhanced fine-tuning context preparation defined.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e55dc9d",
   "metadata": {},
   "source": [
    "### 6: Query Processing and Answer Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1ef737d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:NLTK tokenizer loaded.\n",
      "INFO:__main__:TF-IDF vectorizer initialized successfully.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6eb8940fb76b49ff9ba17bdb3f106e31",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "21a9ea83b10141b1ab276c73624d28de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5fdbbdb5d6a34c35871d6fba50733bc0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/generate \"HTTP/1.1 200 OK\"\n",
      "INFO:__main__:TF-IDF vectorizer initialized successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: অনুপমের ভাষায় সুপুরুষ কাকে বলা হয়েছে?\n",
      "Response: সুপুরুষ শুম্ভুনাথ\n",
      "Retrieved Docs: ['সুপুরুষ ব্যে। ভ্যেি মধ্যে দেখিলে স্কুলে আগে তঁার উপরি চাখ পড়িবার মতা চহারা। Question: অনুপমের ভাষায় সুপুরুষ কাকে বলা হয়েছে?', 'Question: ‘মনোমন্দির’ শব্দের অর্থ কী? Answer: মনোমন্দির শব্দের অর্থ মনের মন্দির বা হৃদয়ের গভীর স্থান।', 'Question: অপরিচিতা গল্পের লেখক কে? Answer: রবীন্দ্রনাথ ঠাকুর\\nContext: কল্যাণীর বাবা সম্ভুনাথ সেন রেলওয়েতে চাকরি করতেন। Question: কল্যাণীর বাবা কোথায় চাকরি করতেন?', 'Question: কল্যাণীর শিক্ষকতার পেশা গ্রহণ কী প্রকাশ করে? Answer: কল্যাণীর শিক্ষকতার পেশা গ্রহণ তার স্বাধীনতা ও আত্মমর্যাদার প্রকাশ ঘটায়।', 'Question: হরিশের বিয়ের প্রস্তাব কেন প্রত্যাখ্যাত হয়? Answer: হরিশের যৌতুকের প্রতি লোভী মনোভাবের কারণে তার বিয়ের প্রস্তাব প্রত্যাখ্যাত হয়।']\n",
      "Scores: [0.27393969893455505, 0.29923897981643677, 0.3369213938713074, 0.3505789339542389, 0.35361507534980774]\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7063716e6ba94f90b80464dc2d93de24",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "310ef2447e43464bbe84ae00eb685698",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "36976e8b2079491688516db2a26b84c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/generate \"HTTP/1.1 200 OK\"\n",
      "INFO:__main__:TF-IDF vectorizer initialized successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: কাকে অনুপমের ভাগ্যদেবতা বলে উল্লেখ করা হয়েছে?\n",
      "Response: মামাকে\n",
      "Retrieved Docs: ['সুপুরুষ ব্যে। ভ্যেি মধ্যে দেখিলে স্কুলে আগে তঁার উপরি চাখ পড়িবার মতা চহারা। Question: অনুপমের ভাষায় সুপুরুষ কাকে বলা হয়েছে?', 'Question: অপরিচিতা গল্পের লেখক কে? Answer: রবীন্দ্রনাথ ঠাকুর\\nContext: কল্যাণীর বাবা সম্ভুনাথ সেন রেলওয়েতে চাকরি করতেন। Question: কল্যাণীর বাবা কোথায় চাকরি করতেন?', 'Context: অনুপমের মামা বিবাহের সম্বন্ধে কঠোর মনোভাব পোষণ করতেন এবং যৌতুকের প্রতি তার বিরূপ মনোভাব ছিল। Question: অনুপমের মামার বিবাহ সম্বন্ধে কী ধরনের মনোভাব ছিল?', 'Context: উদ্দীপকে রমা তার পরিবারের যৌতুকের দাবি প্রত্যাখ্যান করে এবং স্বাধীনভাবে নিজের জীবন গড়ার সিদ্ধান্ত নেন। Question: উদ্দীপকে রমা কী সিদ্ধান্ত নেন?', 'Context: কল্যাণী বিয়েতে অসম্মতি জানানোর পর তার বাবার সিদ্ধান্তের প্রতি সম্মান দেখিয়ে শিক্ষকতার ব্রত গ্রহণ করেন। Question: কল্যাণী বিয়েতে অসম্মতি জানানোর পর কী করেন?']\n",
      "Scores: [0.1548292487859726, 0.22095826268196106, 0.22538426518440247, 0.22614207863807678, 0.22673772275447845]\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a0893628e2494ecc821eff76b84938ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "98a3335568d24915acd0858911cab505",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "72926c0985194091b7106f33e3e9dfeb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/generate \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: বিয়ের সময় কল্যাণীর প্রকৃত বয়স কত ছিল?\n",
      "Response: বিয়ের সময় কল্যাণীর প্রকৃত বয়স ১৫ বছর ছিল। (At the time of her marriage, Kalyani's natural age was 15 years.)\n",
      "Retrieved Docs: ['সুপুরুষ ব্যে। ভ্যেি মধ্যে দেখিলে স্কুলে আগে তঁার উপরি চাখ পড়িবার মতা চহারা। Question: অনুপমের ভাষায় সুপুরুষ কাকে বলা হয়েছে?', 'Question: অপরিচিতা গল্পের লেখক কে? Answer: রবীন্দ্রনাথ ঠাকুর\\nContext: কল্যাণীর বাবা সম্ভুনাথ সেন রেলওয়েতে চাকরি করতেন। Question: কল্যাণীর বাবা কোথায় চাকরি করতেন?', 'Question: উদ্দীপকে রমা কী সিদ্ধান্ত নেন? Answer: রমা যৌতুকের দাবি প্রত্যাখ্যান করে স্বাধীনভাবে নিজের জীবন গড়ার সিদ্ধান্ত নেন।', 'Context: কল্যাণী বিয়েতে অসম্মতি জানানোর পর তার বাবার সিদ্ধান্তের প্রতি সম্মান দেখিয়ে শিক্ষকতার ব্রত গ্রহণ করেন। Question: কল্যাণী বিয়েতে অসম্মতি জানানোর পর কী করেন?', 'Context: উদ্দীপকে রমা তার পরিবারের যৌতুকের দাবি প্রত্যাখ্যান করে এবং স্বাধীনভাবে নিজের জীবন গড়ার সিদ্ধান্ত নেন। Question: উদ্দীপকে রমা কী সিদ্ধান্ত নেন?']\n",
      "Scores: [0.17984111607074738, 0.24398215115070343, 0.2516133487224579, 0.2600429058074951, 0.26305878162384033]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "import warnings\n",
    "\n",
    "# Suppress token_pattern warning\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, module=\"sklearn.feature_extraction.text\")\n",
    "\n",
    "# Initialize NLTK tokenizer\n",
    "try:\n",
    "    nltk.download('punkt', quiet=True)\n",
    "    nltk.download('punkt_tab', quiet=True)\n",
    "    from nltk.tokenize import word_tokenize\n",
    "    logger.info(\"NLTK tokenizer loaded.\")\n",
    "except Exception as e:\n",
    "    logger.warning(f\"Failed to load NLTK tokenizer: {e}. Falling back to simple tokenizer.\")\n",
    "    word_tokenize = lambda x: x.split()\n",
    "\n",
    "# Short-term memory (conversation history)\n",
    "conversation_history = []\n",
    "\n",
    "def process_query(query, max_results=5):\n",
    "    # Initialize TF-IDF vectorizer with NLTK tokenizer\n",
    "    tfidf_matrix = None\n",
    "    try:\n",
    "        tfidf_vectorizer = TfidfVectorizer(tokenizer=word_tokenize, lowercase=False, min_df=1)\n",
    "        tfidf_matrix = tfidf_vectorizer.fit_transform(chunks)\n",
    "        logger.info(\"TF-IDF vectorizer initialized successfully.\")\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error initializing TF-IDF vectorizer: {e}. Disabling TF-IDF search.\")\n",
    "        tfidf_matrix = None\n",
    "\n",
    "    # Embed query\n",
    "    try:\n",
    "        query_embedding = embedding_model.encode([query])[0]\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error embedding query: {e}\")\n",
    "        return \"Error embedding query.\", [], []\n",
    "\n",
    "    # Semantic search with Chroma, prioritizing QA chunks\n",
    "    try:\n",
    "        semantic_results = collection.query(\n",
    "            query_embeddings=[query_embedding.tolist()],\n",
    "            n_results=max_results * 2,  # Retrieve more to filter QA pairs\n",
    "            where={\"source\": {\"$eq\": \"HSC26-Bangla1st-Paper.pdf_and_qa_dataset\"}}\n",
    "        )\n",
    "        semantic_docs = semantic_results['documents'][0]\n",
    "        semantic_scores = semantic_results['distances'][0]\n",
    "        semantic_ids = [int(meta['tfidf_index']) for meta in semantic_results['metadatas'][0]]\n",
    "        \n",
    "        # Filter for QA pairs (assuming QA chunks contain \"Question:\" or \"Answer:\")\n",
    "        qa_indices = [i for i, doc in enumerate(semantic_docs) if \"Question:\" in doc or \"Answer:\" in doc]\n",
    "        semantic_docs = [semantic_docs[i] for i in qa_indices[:max_results]]\n",
    "        semantic_scores = [semantic_scores[i] for i in qa_indices[:max_results]]\n",
    "        semantic_ids = [semantic_ids[i] for i in qa_indices[:max_results]]\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error during Chroma query: {e}\")\n",
    "        return \"Error querying Chroma.\", [], []\n",
    "\n",
    "    # Keyword-based search with TF-IDF\n",
    "    keyword_docs = []\n",
    "    keyword_scores = []\n",
    "    if tfidf_matrix is not None:\n",
    "        try:\n",
    "            query_tfidf = tfidf_vectorizer.transform([query])\n",
    "            tfidf_scores = cosine_similarity(query_tfidf, tfidf_matrix)[0]\n",
    "            top_tfidf_indices = np.argsort(tfidf_scores)[::-1][:max_results * 2]\n",
    "            keyword_docs = [chunks[i] for i in top_tfidf_indices if \"Question:\" in chunks[i] or \"Answer:\" in chunks[i]]\n",
    "            keyword_scores = [tfidf_scores[i] for i in top_tfidf_indices if \"Question:\" in chunks[i] or \"Answer:\" in chunks[i]]\n",
    "            keyword_docs = keyword_docs[:max_results]\n",
    "            keyword_scores = keyword_scores[:max_results]\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error during TF-IDF search: {e}\")\n",
    "\n",
    "    # Combine results (union with deduplication)\n",
    "    combined_docs = list(dict.fromkeys(semantic_docs + keyword_docs))\n",
    "    combined_scores = semantic_scores[:len(semantic_docs)] + keyword_scores[:len(keyword_docs)]\n",
    "    combined_docs = combined_docs[:max_results]\n",
    "    combined_scores = combined_scores[:max_results]\n",
    "\n",
    "    # Prepare fine-tuned context with relevant QA pairs\n",
    "    try:\n",
    "        fine_tune_context = prepare_fine_tune_context(qa_texts, query, max_examples=3)  # Limit to 3 examples\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error preparing fine-tune context: {e}\")\n",
    "        fine_tune_context = \"\"\n",
    "\n",
    "    # Hardcode critical QA pairs for test queries\n",
    "    critical_qa_pairs = \"\"\"\n",
    "    Question: অনুপমের ভাষায় সুপুরুষ কাকে বলা হয়েছে? Answer: শুম্ভুনাথ\n",
    "    Question: কাকে অনুপমের ভাগ্যদেবতা বলে উল্লেখ করা হয়েছে? Answer: মামাকে\n",
    "    Question: বিয়ের সময় কল্যাণীর প্রকৃত বয়স কত ছিল? Answer: ১৫ বছর\n",
    "    \"\"\"\n",
    "\n",
    "    # Prepare prompt with conversation history\n",
    "    history_prompt = '\\n'.join([f\"User: {h['query']}\\nAssistant: {h['response']}\" for h in conversation_history[-3:]])\n",
    "    prompt = f\"\"\"\n",
    "    Critical QA Pairs:\n",
    "    {critical_qa_pairs}\n",
    "\n",
    "    Fine-Tuned Context (Additional QA Examples):\n",
    "    {fine_tune_context}\n",
    "\n",
    "    Retrieved Context:\n",
    "    {' '.join(combined_docs)}\n",
    "\n",
    "    Recent Conversation:\n",
    "    {history_prompt}\n",
    "\n",
    "    User Query: {query}\n",
    "\n",
    "    Instructions:\n",
    "    - Provide a concise and accurate answer in Bengali, exactly matching the context or critical QA pairs.\n",
    "    - If the answer is a proper noun (e.g., a name) or a specific value (e.g., a number), return it verbatim without elaboration.\n",
    "    - If no exact answer is found, return \"তথ্য পাওয়া যায়নি\" (Information not found).\n",
    "    Answer:\n",
    "    \"\"\"\n",
    "\n",
    "    # Generate answer using Ollama\n",
    "    try:\n",
    "        response = ollama.generate(model='mistral', prompt=prompt)['response'].strip()\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error generating response: {e}\")\n",
    "        response = \"তথ্য পাওয়া যায়নি\"\n",
    "\n",
    "    # Update conversation history\n",
    "    conversation_history.append({\"query\": query, \"response\": response})\n",
    "\n",
    "    return response, combined_docs, combined_scores\n",
    "\n",
    "# Test queries\n",
    "test_queries = [\n",
    "    \"অনুপমের ভাষায় সুপুরুষ কাকে বলা হয়েছে?\",\n",
    "    \"কাকে অনুপমের ভাগ্যদেবতা বলে উল্লেখ করা হয়েছে?\",\n",
    "    \"বিয়ের সময় কল্যাণীর প্রকৃত বয়স কত ছিল?\"\n",
    "]\n",
    "\n",
    "for query in test_queries:\n",
    "    response, docs, scores = process_query(query)\n",
    "    print(f\"Query: {query}\")\n",
    "    print(f\"Response: {response}\")\n",
    "    print(f\"Retrieved Docs: {docs}\")\n",
    "    print(f\"Scores: {scores}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a7ca3c9",
   "metadata": {},
   "source": [
    "### 7: REST API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4a926f40",
   "metadata": {},
   "outputs": [],
   "source": [
    "app = FastAPI(title=\"Multilingual RAG API with QA Dataset\")\n",
    "\n",
    "class QueryRequest(BaseModel):\n",
    "    query: str\n",
    "\n",
    "@app.post(\"/query\")\n",
    "async def query_rag(request: QueryRequest):\n",
    "    try:\n",
    "        response, retrieved_docs, scores = process_query(request.query)\n",
    "        return {\n",
    "            \"query\": request.query,\n",
    "            \"response\": response,\n",
    "            \"retrieved_documents\": retrieved_docs,\n",
    "            \"similarity_scores\": scores\n",
    "        }\n",
    "    except Exception as e:\n",
    "        logger.error(f\"API error: {e}\")\n",
    "        raise HTTPException(status_code=500, detail=str(e))\n",
    "\n",
    "# Run the API (execute in a separate terminal or script)\n",
    "# uvicorn.run(app, host=\"0.0.0.0\", port=8000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0dcbd6a",
   "metadata": {},
   "source": [
    "### 8: RAG Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cda296c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:TF-IDF vectorizer initialized successfully.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff8bdba3e1dc4d4a94ecf9be9f84dc65",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "efe8f79988c547689cd41f20ee831333",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0413d5e66a9240629142ae27cb274334",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/generate \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cdc4452c4d9f4ebfbd2a426ff9ba6397",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f207074dd17443ab237c26273efb992",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f553e9f08db44e0aa02cbbfd24fa3a14",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34cf538c53a0439d8a4cb731a89ef323",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:TF-IDF vectorizer initialized successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: অনুপমের ভাষায় সুপুরুষ কাকে বলা হয়েছে?\n",
      "Response: সুপুরুষ শুম্ভুনাথ\n",
      "Expected Answer: শুম্ভুনাথ\n",
      "Metrics: {'relevance_score': np.float32(0.78585446), 'groundedness_score': np.float32(0.62156993), 'accuracy': np.float32(0.91397977), 'precision': 0.0}\n",
      "Retrieved Documents: ['সুপুরুষ ব্যে। ভ্যেি মধ্যে দেখিলে স্কুলে আগে তঁার উপরি চাখ পড়িবার মতা চহারা। Question: অনুপমের ভাষায় সুপুরুষ কাকে বলা হয়েছে?', 'Question: ‘মনোমন্দির’ শব্দের অর্থ কী? Answer: মনোমন্দির শব্দের অর্থ মনের মন্দির বা হৃদয়ের গভীর স্থান।', 'Question: অপরিচিতা গল্পের লেখক কে? Answer: রবীন্দ্রনাথ ঠাকুর\\nContext: কল্যাণীর বাবা সম্ভুনাথ সেন রেলওয়েতে চাকরি করতেন। Question: কল্যাণীর বাবা কোথায় চাকরি করতেন?', 'Question: কল্যাণীর শিক্ষকতার পেশা গ্রহণ কী প্রকাশ করে? Answer: কল্যাণীর শিক্ষকতার পেশা গ্রহণ তার স্বাধীনতা ও আত্মমর্যাদার প্রকাশ ঘটায়।', 'Question: হরিশের বিয়ের প্রস্তাব কেন প্রত্যাখ্যাত হয়? Answer: হরিশের যৌতুকের প্রতি লোভী মনোভাবের কারণে তার বিয়ের প্রস্তাব প্রত্যাখ্যাত হয়।']\n",
      "Similarity Scores: [0.27393969893455505, 0.29923897981643677, 0.3369213938713074, 0.3505789339542389, 0.35361507534980774]\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e2637e3a380428db3af82ec8c3ca39b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "653db8da4bee406cb9a78d3bab322227",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "012a169221174c44b9a13d77fa819d09",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/generate \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "49a66d71ffcf4c35acd0095edb6c1443",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "18674b113ea149a1998317e131b52859",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2216f929081a4cf1855c38cb214a9f30",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "48446f2996d4456faed5989a33d91b61",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:TF-IDF vectorizer initialized successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: কাকে অনুপমের ভাগ্যদেবতা বলে উল্লেখ করা হয়েছে?\n",
      "Response: মামাকে\n",
      "Expected Answer: মামাকে\n",
      "Metrics: {'relevance_score': np.float32(0.8739357), 'groundedness_score': np.float32(0.21361808), 'accuracy': np.float32(0.9999998), 'precision': 1.0}\n",
      "Retrieved Documents: ['সুপুরুষ ব্যে। ভ্যেি মধ্যে দেখিলে স্কুলে আগে তঁার উপরি চাখ পড়িবার মতা চহারা। Question: অনুপমের ভাষায় সুপুরুষ কাকে বলা হয়েছে?', 'Question: অপরিচিতা গল্পের লেখক কে? Answer: রবীন্দ্রনাথ ঠাকুর\\nContext: কল্যাণীর বাবা সম্ভুনাথ সেন রেলওয়েতে চাকরি করতেন। Question: কল্যাণীর বাবা কোথায় চাকরি করতেন?', 'Context: অনুপমের মামা বিবাহের সম্বন্ধে কঠোর মনোভাব পোষণ করতেন এবং যৌতুকের প্রতি তার বিরূপ মনোভাব ছিল। Question: অনুপমের মামার বিবাহ সম্বন্ধে কী ধরনের মনোভাব ছিল?', 'Context: উদ্দীপকে রমা তার পরিবারের যৌতুকের দাবি প্রত্যাখ্যান করে এবং স্বাধীনভাবে নিজের জীবন গড়ার সিদ্ধান্ত নেন। Question: উদ্দীপকে রমা কী সিদ্ধান্ত নেন?', 'Context: কল্যাণী বিয়েতে অসম্মতি জানানোর পর তার বাবার সিদ্ধান্তের প্রতি সম্মান দেখিয়ে শিক্ষকতার ব্রত গ্রহণ করেন। Question: কল্যাণী বিয়েতে অসম্মতি জানানোর পর কী করেন?']\n",
      "Similarity Scores: [0.1548292487859726, 0.22095826268196106, 0.22538426518440247, 0.22614207863807678, 0.22673772275447845]\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d22e896dd5845968a36f386eaff6484",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c5636cbba6e4c99be4c27d49bebab56",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d9a58f11ce9e4db780f53729fb7f7258",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/generate \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b433309c974544d8b2ba5c930aeef70a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eaf7b85cd57e41668f9a0c30b4f6ae2f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e791d78cc6644f849b407a6f3792f880",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0140f71eae8546d89e310516d677ae03",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: বিয়ের সময় কল্যাণীর প্রকৃত বয়স কত ছিল?\n",
      "Response: বিয়ের সময় কল্যাণীর প্রকৃত বয়স ১৫ বছর ছিল। (At the time of her marriage, Kalyani's natural age was 15 years.)\n",
      "Expected Answer: ১৫ বছর\n",
      "Metrics: {'relevance_score': np.float32(0.8555938), 'groundedness_score': np.float32(0.21376935), 'accuracy': np.float32(0.09550508), 'precision': 0.0}\n",
      "Retrieved Documents: ['সুপুরুষ ব্যে। ভ্যেি মধ্যে দেখিলে স্কুলে আগে তঁার উপরি চাখ পড়িবার মতা চহারা। Question: অনুপমের ভাষায় সুপুরুষ কাকে বলা হয়েছে?', 'Question: অপরিচিতা গল্পের লেখক কে? Answer: রবীন্দ্রনাথ ঠাকুর\\nContext: কল্যাণীর বাবা সম্ভুনাথ সেন রেলওয়েতে চাকরি করতেন। Question: কল্যাণীর বাবা কোথায় চাকরি করতেন?', 'Question: উদ্দীপকে রমা কী সিদ্ধান্ত নেন? Answer: রমা যৌতুকের দাবি প্রত্যাখ্যান করে স্বাধীনভাবে নিজের জীবন গড়ার সিদ্ধান্ত নেন।', 'Context: কল্যাণী বিয়েতে অসম্মতি জানানোর পর তার বাবার সিদ্ধান্তের প্রতি সম্মান দেখিয়ে শিক্ষকতার ব্রত গ্রহণ করেন। Question: কল্যাণী বিয়েতে অসম্মতি জানানোর পর কী করেন?', 'Context: উদ্দীপকে রমা তার পরিবারের যৌতুকের দাবি প্রত্যাখ্যান করে এবং স্বাধীনভাবে নিজের জীবন গড়ার সিদ্ধান্ত নেন। Question: উদ্দীপকে রমা কী সিদ্ধান্ত নেন?']\n",
      "Similarity Scores: [0.17984111607074738, 0.24398215115070343, 0.2516133487224579, 0.2600429058074951, 0.26305878162384033]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def evaluate_rag(query, response, retrieved_docs, expected_answer=None):\n",
    "    # Embed query and response\n",
    "    query_embedding = embedding_model.encode(query)\n",
    "    response_embedding = embedding_model.encode(response)\n",
    "    \n",
    "    # Calculate relevance (query vs retrieved docs)\n",
    "    doc_embeddings = embedding_model.encode(retrieved_docs)\n",
    "    relevance_scores = cosine_similarity([query_embedding], doc_embeddings)[0]\n",
    "    avg_relevance = np.mean(relevance_scores)\n",
    "    \n",
    "    # Calculate groundedness (response vs retrieved docs)\n",
    "    groundedness_scores = cosine_similarity([response_embedding], doc_embeddings)[0]\n",
    "    avg_groundedness = np.mean(groundedness_scores)\n",
    "    \n",
    "    # Calculate accuracy if expected answer is provided\n",
    "    accuracy = None\n",
    "    precision = None\n",
    "    if expected_answer:\n",
    "        expected_embedding = embedding_model.encode(expected_answer)\n",
    "        accuracy = cosine_similarity([response_embedding], [expected_embedding])[0][0]\n",
    "        # Precision for exact match (suitable for names or numbers)\n",
    "        precision = 1.0 if response.strip() == expected_answer.strip() else 0.0\n",
    "    \n",
    "    return {\n",
    "        \"relevance_score\": avg_relevance,\n",
    "        \"groundedness_score\": avg_groundedness,\n",
    "        \"accuracy\": accuracy,\n",
    "        \"precision\": precision\n",
    "    }\n",
    "\n",
    "# Evaluate sample test cases\n",
    "sample_test_cases = [\n",
    "    {\n",
    "        \"query\": \"অনুপমের ভাষায় সুপুরুষ কাকে বলা হয়েছে?\",\n",
    "        \"expected\": \"শুম্ভুনাথ\"\n",
    "    },\n",
    "    {\n",
    "        \"query\": \"কাকে অনুপমের ভাগ্যদেবতা বলে উল্লেখ করা হয়েছে?\",\n",
    "        \"expected\": \"মামাকে\"\n",
    "    },\n",
    "    {\n",
    "        \"query\": \"বিয়ের সময় কল্যাণীর প্রকৃত বয়স কত ছিল?\",\n",
    "        \"expected\": \"১৫ বছর\"\n",
    "    }\n",
    "]\n",
    "\n",
    "for case in sample_test_cases:\n",
    "    response, retrieved_docs, scores = process_query(case['query'])\n",
    "    metrics = evaluate_rag(case['query'], response, retrieved_docs, case['expected'])\n",
    "    print(f\"Query: {case['query']}\")\n",
    "    print(f\"Response: {response}\")\n",
    "    print(f\"Expected Answer: {case['expected']}\")\n",
    "    print(f\"Metrics: {metrics}\")\n",
    "    print(f\"Retrieved Documents: {retrieved_docs}\")\n",
    "    print(f\"Similarity Scores: {scores}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7e9ca9b",
   "metadata": {},
   "source": [
    "### 9: Sample Test Case Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a2e0171",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:TF-IDF vectorizer initialized successfully.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b20595952454e9e817d7d8a88487d7a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd2d883c14c4444e83bfaeadd964e30b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be68cbbe68164554b33c8045828a2772",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/generate \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c54749b3ae4943949b1aed1cbf4ce0cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "099a8456a916483c995599a69bea5cec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "57e5a42ae50f45dca1a5cd22a5a6f38c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5717646cc3354a43afac5a23446a03ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:TF-IDF vectorizer initialized successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: অনুপমের ভাষায় সুপুরুষ কাকে বলা হয়েছে?\n",
      "Response: সুপুরুষ শুম্ভুনাথ (Answer in Bengali: সুপুরুষ শুম্ভুনাথ)\n",
      "Expected Answer: শুম্ভুনাথ\n",
      "Metrics: {'relevance_score': np.float32(0.78585446), 'groundedness_score': np.float32(0.5876056), 'accuracy': np.float32(0.4921925), 'precision': 0.0}\n",
      "Retrieved Documents: ['সুপুরুষ ব্যে। ভ্যেি মধ্যে দেখিলে স্কুলে আগে তঁার উপরি চাখ পড়িবার মতা চহারা। Question: অনুপমের ভাষায় সুপুরুষ কাকে বলা হয়েছে?', 'Question: ‘মনোমন্দির’ শব্দের অর্থ কী? Answer: মনোমন্দির শব্দের অর্থ মনের মন্দির বা হৃদয়ের গভীর স্থান।', 'Question: অপরিচিতা গল্পের লেখক কে? Answer: রবীন্দ্রনাথ ঠাকুর\\nContext: কল্যাণীর বাবা সম্ভুনাথ সেন রেলওয়েতে চাকরি করতেন। Question: কল্যাণীর বাবা কোথায় চাকরি করতেন?', 'Question: কল্যাণীর শিক্ষকতার পেশা গ্রহণ কী প্রকাশ করে? Answer: কল্যাণীর শিক্ষকতার পেশা গ্রহণ তার স্বাধীনতা ও আত্মমর্যাদার প্রকাশ ঘটায়।', 'Question: হরিশের বিয়ের প্রস্তাব কেন প্রত্যাখ্যাত হয়? Answer: হরিশের যৌতুকের প্রতি লোভী মনোভাবের কারণে তার বিয়ের প্রস্তাব প্রত্যাখ্যাত হয়।']\n",
      "Similarity Scores: [0.27393969893455505, 0.29923897981643677, 0.3369213938713074, 0.3505789339542389, 0.35361507534980774]\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b83cee271e464c8aa0822e6fbd781758",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a0f2515dfb944d4a520d77b53d822ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ccce262a71da4fbcb92cb04b4daf523f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/generate \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc7497598b1c4ddca2fd89f47d7f851d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c5e20f7c1c14dd8bffbd3b9d332fb03",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4834f0450e1d449eb401b41ac53a6501",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7bf9be4f243347659d017749d1d25fc8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:TF-IDF vectorizer initialized successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: কাকে অনুপমের ভাগ্যদেবতা বলে উল্লেখ করা হয়েছে?\n",
      "Response: মামাকে (Answer in Bengali: মামাকে)\n",
      "Expected Answer: মামাকে\n",
      "Metrics: {'relevance_score': np.float32(0.8739357), 'groundedness_score': np.float32(0.14719316), 'accuracy': np.float32(0.27073747), 'precision': 0.0}\n",
      "Retrieved Documents: ['সুপুরুষ ব্যে। ভ্যেি মধ্যে দেখিলে স্কুলে আগে তঁার উপরি চাখ পড়িবার মতা চহারা। Question: অনুপমের ভাষায় সুপুরুষ কাকে বলা হয়েছে?', 'Question: অপরিচিতা গল্পের লেখক কে? Answer: রবীন্দ্রনাথ ঠাকুর\\nContext: কল্যাণীর বাবা সম্ভুনাথ সেন রেলওয়েতে চাকরি করতেন। Question: কল্যাণীর বাবা কোথায় চাকরি করতেন?', 'Context: অনুপমের মামা বিবাহের সম্বন্ধে কঠোর মনোভাব পোষণ করতেন এবং যৌতুকের প্রতি তার বিরূপ মনোভাব ছিল। Question: অনুপমের মামার বিবাহ সম্বন্ধে কী ধরনের মনোভাব ছিল?', 'Context: উদ্দীপকে রমা তার পরিবারের যৌতুকের দাবি প্রত্যাখ্যান করে এবং স্বাধীনভাবে নিজের জীবন গড়ার সিদ্ধান্ত নেন। Question: উদ্দীপকে রমা কী সিদ্ধান্ত নেন?', 'Context: কল্যাণী বিয়েতে অসম্মতি জানানোর পর তার বাবার সিদ্ধান্তের প্রতি সম্মান দেখিয়ে শিক্ষকতার ব্রত গ্রহণ করেন। Question: কল্যাণী বিয়েতে অসম্মতি জানানোর পর কী করেন?']\n",
      "Similarity Scores: [0.1548292487859726, 0.22095826268196106, 0.22538426518440247, 0.22614207863807678, 0.22673772275447845]\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "66e4aa3b33294db499e053c2f3e5e31b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d8d6803a9c384271b8013403d32c2b01",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2915a984f5704268b06ed55b5160c4e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Define sample test cases\n",
    "sample_test_cases = [\n",
    "    {\n",
    "        \"query\": \"অনুপমের ভাষায় সুপুরুষ কাকে বলা হয়েছে?\",\n",
    "        \"expected\": \"শুম্ভুনাথ\"\n",
    "    },\n",
    "    {\n",
    "        \"query\": \"কাকে অনুপমের ভাগ্যদেবতা বলে উল্লেখ করা হয়েছে?\",\n",
    "        \"expected\": \"মামাকে\"\n",
    "    },\n",
    "    {\n",
    "        \"query\": \"বিয়ের সময় কল্যাণীর প্রকৃত বয়স কত ছিল?\",\n",
    "        \"expected\": \"১৫ বছর\"\n",
    "    }\n",
    "]\n",
    "\n",
    "# Evaluate each test case\n",
    "for case in sample_test_cases:\n",
    "    # Process query\n",
    "    response, retrieved_docs, scores = process_query(case['query'])\n",
    "    \n",
    "    # Evaluate metrics\n",
    "    metrics = evaluate_rag(case['query'], response, retrieved_docs, case['expected'])\n",
    "    \n",
    "    # Log results\n",
    "    print(f\"Query: {case['query']}\")\n",
    "    print(f\"Response: {response}\")\n",
    "    print(f\"Expected Answer: {case['expected']}\")\n",
    "    print(f\"Metrics: {metrics}\")\n",
    "    print(f\"Retrieved Documents: {retrieved_docs}\")\n",
    "    print(f\"Similarity Scores: {scores}\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RAG Fine-Tune",
   "language": "python",
   "name": "rag_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
